{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/shyel/repositories/mamba_linear_code\")\n",
    "os.chdir(\"/home/shyel/repositories/mamba_linear_code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDPC_N49_K24.alist\n"
     ]
    }
   ],
   "source": [
    "from configuration import Code, Config\n",
    "from dataset import get_generator_and_parity\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "\n",
    "def code_from_hint(hint,):\n",
    "    code_files = os.listdir(CODES_PATH)\n",
    "    code_files = [f for f in code_files if hint in f][0]\n",
    "    print(code_files)\n",
    "    code_n = int(code_files.split('_')[1][1:])\n",
    "    code_k = int(code_files.split('_')[-1][1:].split('.')[0])\n",
    "    code_type = code_files.split('_')[0]\n",
    "    code = Code(code_n, code_k, code_type)\n",
    "    return code\n",
    "\n",
    "OUTPUT_PATH = \".semi-working-mamba-mask-large-bidir/.output-8/\"\n",
    "CODES_PATH = \"codes/\"\n",
    "example_code = code_from_hint(\"LDPC_N49_K24\")\n",
    "G,H = get_generator_and_parity(example_code, standard_form=True)\n",
    "example_code.generator_matrix = torch.from_numpy(G).transpose(0,1).long()\n",
    "example_code.pc_matrix = torch.from_numpy(H).long()\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "config = Config(\n",
    "    code=example_code,\n",
    "    d_model=128, # example_code.n + H.shape[0],\n",
    "    path=OUTPUT_PATH,\n",
    "    N_dec=8,\n",
    "    warmup_lr=1.0e-3,\n",
    "    lr=5e-4,\n",
    "    epochs=1000,\n",
    "    eta_min=1e-12,\n",
    "    batch_size=64,\n",
    "    gradient_clipping=1.0\n",
    ")\n",
    "\n",
    "handlers = [\n",
    "        logging.FileHandler(os.path.join(OUTPUT_PATH, 'logging.txt')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s',\n",
    "                    handlers=handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyel/repositories/mamba_linear_code/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mamba_ssm import Mamba\n",
    "from dataset import EbN0_to_std, ECC_Dataset, train, test, sign_to_bin, FER, BER, bin_to_sign\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, LayerNorm\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from mamba_ssm.ops.selective_scan_interface import selective_scan_fn, mamba_inner_fn\n",
    "\n",
    "try:\n",
    "    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\n",
    "except ImportError:\n",
    "    causal_conv1d_fn, causal_conv1d_update = None, None\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.selective_state_update import selective_state_update\n",
    "except ImportError:\n",
    "    selective_state_update = None\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layer_norm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "\n",
    "# ECCM\n",
    "from configuration import Code, Config\n",
    "import numpy as np\n",
    "\n",
    "from dataset import sign_to_bin, bin_to_sign\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList\n",
    "import copy\n",
    "\n",
    "def build_mask(code):\n",
    "    mask_size = code.n + code.pc_matrix.size(0)\n",
    "    mask = torch.eye(mask_size, mask_size)\n",
    "    for ii in range(code.pc_matrix.size(0)):\n",
    "        idx = torch.where(code.pc_matrix[ii] > 0)[0]\n",
    "        for jj in idx:\n",
    "            for kk in idx:\n",
    "                if jj != kk:\n",
    "                    mask[jj, kk] += 1\n",
    "                    mask[kk, jj] += 1\n",
    "                    mask[code.n + ii, jj] += 1\n",
    "                    mask[jj, code.n + ii] += 1\n",
    "    src_mask = ~ (mask > 0)\n",
    "    return src_mask\n",
    "\n",
    "def mask_larger_matrix(M, mask):\n",
    "    M[:, :mask.size(0), :mask.size(1)][mask.expand(M.size(0),mask.size(0),mask.size(1))] = 0.0\n",
    "    M[:, mask.size(0):, mask.size(1):] = 0\n",
    "    return M\n",
    "\n",
    "def mask(A,B,C,D, mask):\n",
    "    B = mask_larger_matrix(B, mask)\n",
    "    C = mask_larger_matrix(C, mask)\n",
    "    return A, B, C, D\n",
    "\n",
    "def mamba_inner_fn(\n",
    "    xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
    "    out_proj_weight, out_proj_bias,\n",
    "    pc_mask, A, B=None, C=None, D=None, delta_bias=None, B_proj_bias=None,\n",
    "    C_proj_bias=None, delta_softplus=True\n",
    "):\n",
    "    assert causal_conv1d_fn is not None, \"causal_conv1d_fn is not available. Please install causal-conv1d.\"\n",
    "    L = xz.shape[-1]\n",
    "    delta_rank = delta_proj_weight.shape[1]\n",
    "    d_state = A.shape[-1] * (1 if not A.is_complex() else 2)\n",
    "    x, z = xz.chunk(2, dim=1)\n",
    "    x = causal_conv1d_fn(x, rearrange(conv1d_weight, \"d 1 w -> d w\"), conv1d_bias, activation=\"silu\")\n",
    "    # We're being very careful here about the layout, to avoid extra transposes.\n",
    "    # We want delta to have d as the slowest moving dimension\n",
    "    # and L as the fastest moving dimension, since those are what the ssm_scan kernel expects.\n",
    "    x_dbl = F.linear(rearrange(x, 'b d l -> (b l) d'), x_proj_weight)  # (bl d)\n",
    "    delta = delta_proj_weight @ x_dbl[:, :delta_rank].t()\n",
    "    delta = rearrange(delta, \"d (b l) -> b d l\", l=L)\n",
    "    if B is None:  # variable B\n",
    "        B = x_dbl[:, delta_rank:delta_rank + d_state]  # (bl d)\n",
    "        if B_proj_bias is not None:\n",
    "            B = B + B_proj_bias.to(dtype=B.dtype)\n",
    "        if not A.is_complex():\n",
    "            B = rearrange(B, \"(b l) dstate -> b dstate l\", l=L).contiguous()\n",
    "        else:\n",
    "            B = rearrange(B, \"(b l) (dstate two) -> b dstate (l two)\", l=L, two=2).contiguous()\n",
    "    if C is None:  # variable B\n",
    "        C = x_dbl[:, -d_state:]  # (bl d)\n",
    "        if C_proj_bias is not None:\n",
    "            C = C + C_proj_bias.to(dtype=C.dtype)\n",
    "        if not A.is_complex():\n",
    "            C = rearrange(C, \"(b l) dstate -> b dstate l\", l=L).contiguous()\n",
    "        else:\n",
    "            C = rearrange(C, \"(b l) (dstate two) -> b dstate (l two)\", l=L, two=2).contiguous()\n",
    "    # mask\n",
    "    A,B,C,D = mask(A,B,C,D,pc_mask)\n",
    "    y = selective_scan_fn(x, delta, A, B, C, D, z=z, delta_bias=delta_bias, delta_softplus=True)\n",
    "    mask_larger_matrix(y, pc_mask)\n",
    "    return F.linear(rearrange(y, \"b d l -> b l d\"), out_proj_weight, out_proj_bias)\n",
    "\n",
    "\n",
    "class ECCMLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        code: Code,\n",
    "        d_model=16,\n",
    "        d_conv=4,\n",
    "        expand=1,\n",
    "        dt_rank=\"auto\",\n",
    "        dt_min=0.001,\n",
    "        dt_max=0.1,\n",
    "        dt_init=\"random\",\n",
    "        dt_scale=1.0,\n",
    "        dt_init_floor=1e-4,\n",
    "        conv_bias=True,\n",
    "        bias=False,\n",
    "        use_fast_path=True,  # Fused kernel options\n",
    "        layer_idx=None,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.code_length = code.n\n",
    "        self.output_length = self.code_length + code.pc_matrix.size(0)\n",
    "        d_state = int(2**np.ceil(np.log2(self.output_length)))\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert self.d_model * expand >= self.output_length, f\"d_model * expand {self.d_model * expand} must be larger than the output length, (code_length + syndrome length).\"\n",
    "        self.d_state = d_state\n",
    "        self.d_conv = d_conv\n",
    "        self.expand = expand\n",
    "        self.d_inner = int(self.expand * self.d_model)\n",
    "        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == \"auto\" else dt_rank\n",
    "        self.use_fast_path = use_fast_path\n",
    "        self.layer_idx = layer_idx\n",
    "\n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_inner * 2, bias=bias, **factory_kwargs)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.d_inner,\n",
    "            out_channels=self.d_inner,\n",
    "            bias=conv_bias,\n",
    "            kernel_size=d_conv,\n",
    "            groups=self.d_inner,\n",
    "            padding=d_conv - 1,\n",
    "            **factory_kwargs,\n",
    "        )\n",
    "\n",
    "        self.activation = \"silu\"\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "        self.x_proj = nn.Linear(\n",
    "            self.d_inner, self.dt_rank + self.d_state * 2, bias=False, **factory_kwargs\n",
    "        )\n",
    "        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True, **factory_kwargs)\n",
    "\n",
    "        # Initialize special dt projection to preserve variance at initialization\n",
    "        dt_init_std = self.dt_rank**-0.5 * dt_scale\n",
    "        if dt_init == \"constant\":\n",
    "            nn.init.constant_(self.dt_proj.weight, dt_init_std)\n",
    "        elif dt_init == \"random\":\n",
    "            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Initialize dt bias so that F.softplus(dt_bias) is between dt_min and dt_max\n",
    "        dt = torch.exp(\n",
    "            torch.rand(self.d_inner, **factory_kwargs) * (math.log(dt_max) - math.log(dt_min))\n",
    "            + math.log(dt_min)\n",
    "        ).clamp(min=dt_init_floor)\n",
    "        # Inverse of softplus: https://github.com/pytorch/pytorch/issues/72759\n",
    "        inv_dt = dt + torch.log(-torch.expm1(-dt))\n",
    "        with torch.no_grad():\n",
    "            self.dt_proj.bias.copy_(inv_dt)\n",
    "        # Our initialization would set all Linear.bias to zero, need to mark this one as _no_reinit\n",
    "        self.dt_proj.bias._no_reinit = True\n",
    "\n",
    "        # S4D real initialization\n",
    "        A = repeat(\n",
    "            torch.arange(1, self.d_state + 1, dtype=torch.float32, device=device),\n",
    "            \"n -> d n\",\n",
    "            d=self.d_inner,\n",
    "        ).contiguous()\n",
    "        A_log = torch.log(A)  # Keep A_log in fp32\n",
    "        self.A_log = nn.Parameter(A_log)\n",
    "        self.A_log._no_weight_decay = True\n",
    "\n",
    "        # D \"skip\" parameter\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner, device=device))  # Keep in fp32\n",
    "        self.D._no_weight_decay = True\n",
    "\n",
    "        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=bias, **factory_kwargs)\n",
    "\n",
    "    def forward(self, hidden_states, pc_mask, inference_params=None):\n",
    "        \"\"\"\n",
    "        hidden_states: (B, L, D)\n",
    "        pc_mask: (L, P)\n",
    "        Returns: same shape as hidden_states\n",
    "        \"\"\"\n",
    "        batch, seqlen, dim = hidden_states.shape\n",
    "\n",
    "        conv_state, ssm_state = None, None\n",
    "        if inference_params is not None:\n",
    "            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)\n",
    "            if inference_params.seqlen_offset > 0:\n",
    "                # The states are updated inplace\n",
    "                out, _, _ = self.step(hidden_states, conv_state, ssm_state)\n",
    "                return out\n",
    "\n",
    "        # We do matmul and transpose BLH -> HBL at the same time\n",
    "        xz = rearrange(\n",
    "            self.in_proj.weight @ rearrange(hidden_states, \"b l d -> d (b l)\"),\n",
    "            \"d (b l) -> b d l\",\n",
    "            l=seqlen,\n",
    "        )\n",
    "        if self.in_proj.bias is not None:\n",
    "            xz = xz + rearrange(self.in_proj.bias.to(dtype=xz.dtype), \"d -> d 1\")\n",
    "\n",
    "        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)\n",
    "        # In the backward pass we write dx and dz next to each other to avoid torch.cat\n",
    "        if self.use_fast_path and causal_conv1d_fn is not None and inference_params is None:  # Doesn't support outputting the states\n",
    "            out = mamba_inner_fn(\n",
    "                xz,\n",
    "                self.conv1d.weight,\n",
    "                self.conv1d.bias,\n",
    "                self.x_proj.weight,\n",
    "                self.dt_proj.weight,\n",
    "                self.out_proj.weight,\n",
    "                self.out_proj.bias,\n",
    "                pc_mask,\n",
    "                A,\n",
    "                None,  # input-dependent B\n",
    "                None,  # input-dependent C\n",
    "                self.D.float(),\n",
    "                delta_bias=self.dt_proj.bias.float(),\n",
    "                delta_softplus=True,\n",
    "            )\n",
    "        else:\n",
    "            x, z = xz.chunk(2, dim=1)\n",
    "            # Compute short convolution\n",
    "            if conv_state is not None:\n",
    "                # If we just take x[:, :, -self.d_conv :], it will error if seqlen < self.d_conv\n",
    "                # Instead F.pad will pad with zeros if seqlen < self.d_conv, and truncate otherwise.\n",
    "                conv_state.copy_(F.pad(x, (self.d_conv - x.shape[-1], 0)))  # Update state (B D W)\n",
    "            if causal_conv1d_fn is None:\n",
    "                x = self.act(self.conv1d(x)[..., :seqlen])\n",
    "            else:\n",
    "                assert self.activation in [\"silu\", \"swish\"]\n",
    "                x = causal_conv1d_fn(\n",
    "                    x=x,\n",
    "                    weight=rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n",
    "                    bias=self.conv1d.bias,\n",
    "                    activation=self.activation,\n",
    "                )\n",
    "\n",
    "            # We're careful here about the layout, to avoid extra transposes.\n",
    "            # We want dt to have d as the slowest moving dimension\n",
    "            # and L as the fastest moving dimension, since those are what the ssm_scan kernel expects.\n",
    "            x_dbl = self.x_proj(rearrange(x, \"b d l -> (b l) d\"))  # (bl d)\n",
    "            dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)\n",
    "            dt = self.dt_proj.weight @ dt.t()\n",
    "            dt = rearrange(dt, \"d (b l) -> b d l\", l=seqlen)\n",
    "            B = rearrange(B, \"(b l) dstate -> b dstate l\", l=seqlen).contiguous()\n",
    "            C = rearrange(C, \"(b l) dstate -> b dstate l\", l=seqlen).contiguous()\n",
    "            assert self.activation in [\"silu\", \"swish\"]\n",
    "            D = self.D.float()\n",
    "            A,B,C,D = mask(A,B,C,D, pc_mask)\n",
    "            \n",
    "            y = selective_scan_fn(\n",
    "                x,\n",
    "                dt,\n",
    "                A,\n",
    "                B,\n",
    "                C,\n",
    "                D,\n",
    "                z=z,\n",
    "                delta_bias=self.dt_proj.bias.float(),\n",
    "                delta_softplus=True,\n",
    "                return_last_state=ssm_state is not None,\n",
    "            )\n",
    "            if ssm_state is not None:\n",
    "                y, last_state = y\n",
    "                ssm_state.copy_(last_state)\n",
    "            y = rearrange(y, \"b d l -> b l d\")\n",
    "            mask_larger_matrix(y, pc_mask)\n",
    "            out = self.out_proj(y)\n",
    "        return out\n",
    "\n",
    "    def step(self, hidden_states, conv_state, ssm_state, pc_mask):\n",
    "        dtype = hidden_states.dtype\n",
    "        assert hidden_states.shape[1] == 1, \"Only support decoding with 1 token at a time for now\"\n",
    "        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)\n",
    "        x, z = xz.chunk(2, dim=-1)  # (B D)\n",
    "\n",
    "        # Conv step\n",
    "        if causal_conv1d_update is None:\n",
    "            conv_state.copy_(torch.roll(conv_state, shifts=-1, dims=-1))  # Update state (B D W)\n",
    "            conv_state[:, :, -1] = x\n",
    "            x = torch.sum(conv_state * rearrange(self.conv1d.weight, \"d 1 w -> d w\"), dim=-1)  # (B D)\n",
    "            if self.conv1d.bias is not None:\n",
    "                x = x + self.conv1d.bias\n",
    "            x = self.act(x).to(dtype=dtype)\n",
    "        else:\n",
    "            x = causal_conv1d_update(\n",
    "                x,\n",
    "                conv_state,\n",
    "                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n",
    "                self.conv1d.bias,\n",
    "                self.activation,\n",
    "            )\n",
    "\n",
    "        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)\n",
    "        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)\n",
    "        # Don't add dt_bias here\n",
    "        dt = F.linear(dt, self.dt_proj.weight)  # (B d_inner)\n",
    "        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)\n",
    "\n",
    "        D = self.D.float()\n",
    "        A,B,C,D = mask(A,B,C,D,pc_mask)\n",
    "            \n",
    "        # SSM step\n",
    "        if selective_state_update is None:\n",
    "            # Discretize A and B\n",
    "            dt = F.softplus(dt + self.dt_proj.bias.to(dtype=dt.dtype))\n",
    "            dA = torch.exp(torch.einsum(\"bd,dn->bdn\", dt, A))\n",
    "            dB = torch.einsum(\"bd,bn->bdn\", dt, B)\n",
    "            ssm_state.copy_(ssm_state * dA + rearrange(x, \"b d -> b d 1\") * dB)\n",
    "            y = torch.einsum(\"bdn,bn->bd\", ssm_state.to(dtype), C)\n",
    "            y = y + D.to(dtype) * x\n",
    "            y = y * self.act(z)  # (B D)\n",
    "        else:\n",
    "            y = selective_state_update(\n",
    "                ssm_state, x, dt, A, B, C, D, z=z, dt_bias=self.dt_proj.bias, dt_softplus=True\n",
    "            )\n",
    "\n",
    "        mask_larger_matrix(y, pc_mask)\n",
    "        out = self.out_proj(y)\n",
    "        return out.unsqueeze(1), conv_state, ssm_state\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        device = self.out_proj.weight.device\n",
    "        conv_dtype = self.conv1d.weight.dtype if dtype is None else dtype\n",
    "        conv_state = torch.zeros(\n",
    "            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype\n",
    "        )\n",
    "        ssm_dtype = self.dt_proj.weight.dtype if dtype is None else dtype\n",
    "        # ssm_dtype = torch.float32\n",
    "        ssm_state = torch.zeros(\n",
    "            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype\n",
    "        )\n",
    "        return conv_state, ssm_state\n",
    "\n",
    "    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):\n",
    "        assert self.layer_idx is not None\n",
    "        if self.layer_idx not in inference_params.key_value_memory_dict:\n",
    "            batch_shape = (batch_size,)\n",
    "            conv_state = torch.zeros(\n",
    "                batch_size,\n",
    "                self.d_model * self.expand,\n",
    "                self.d_conv,\n",
    "                device=self.conv1d.weight.device,\n",
    "                dtype=self.conv1d.weight.dtype,\n",
    "            )\n",
    "            ssm_state = torch.zeros(\n",
    "                batch_size,\n",
    "                self.d_model * self.expand,\n",
    "                self.d_state,\n",
    "                device=self.dt_proj.weight.device,\n",
    "                dtype=self.dt_proj.weight.dtype,\n",
    "                # dtype=torch.float32,\n",
    "            )\n",
    "            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)\n",
    "        else:\n",
    "            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]\n",
    "            # TODO: What if batch size changes between generation, and we reuse the same states?\n",
    "            if initialize_states:\n",
    "                conv_state.zero_()\n",
    "                ssm_state.zero_()\n",
    "        return conv_state, ssm_state\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def build_mask(code):\n",
    "    mask_size = code.n + code.pc_matrix.size(0)\n",
    "    mask = torch.eye(mask_size, mask_size)\n",
    "    for ii in range(code.pc_matrix.size(0)):\n",
    "        idx = torch.where(code.pc_matrix[ii] > 0)[0]\n",
    "        for jj in idx:\n",
    "            for kk in idx:\n",
    "                if jj != kk:\n",
    "                    mask[jj, kk] += 1\n",
    "                    mask[kk, jj] += 1\n",
    "                    mask[code.n + ii, jj] += 1\n",
    "                    mask[jj, code.n + ii] += 1\n",
    "    src_mask = ~ (mask > 0)\n",
    "    return src_mask\n",
    "\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, config: Config) -> None:\n",
    "        super().__init__()\n",
    "        self.syndrom_length = config.code.pc_matrix.size(0)\n",
    "        self.n = config.code.n\n",
    "        self.register_buffer('pc_mask', build_mask(config.code))\n",
    "        self.mamba = ECCMLayer(\n",
    "            code=config.code,\n",
    "            d_model=config.d_model,\n",
    "        )\n",
    "        self.src_embed = torch.nn.Parameter(torch.ones(\n",
    "            (self.n + self.syndrom_length, config.d_model)))\n",
    "        # self.up_output_dim = torch.nn.Linear(config.d_model, self.n + self.syndrom_length)\n",
    "        # self.resize_output_dim = torch.nn.Linear(self.n + self.syndrom_length, 1)\n",
    "        # self.norm_output = LayerNorm((self.n,))\n",
    "        self.resize_output_dim = torch.nn.Linear(config.d_model, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb: torch.Tensor = self.src_embed.unsqueeze(0) * x\n",
    "        mamba_forward_out = self.mamba.forward(emb, self.pc_mask)\n",
    "        mamba_reverse_out = self.mamba.forward(torch.flip(emb,[1]), torch.flip(self.pc_mask, [1]))\n",
    "        mamba_out = mamba_forward_out + torch.flip(mamba_reverse_out, [1])\n",
    "        # up_convert_out: torch.Tensor = self.up_output_dim(mamba_out)\n",
    "        # gated_output = up_convert_out.masked_fill(self.pc_mask.bool(), 0.0)\n",
    "        # out_dim_corrected: torch.Tensor = self.resize_output_dim(gated_output).squeeze(0)\n",
    "        out_dim_corrected = self.resize_output_dim(mamba_out)\n",
    "        return F.tanh(out_dim_corrected)\n",
    "\n",
    "class ECCM(torch.nn.Module):\n",
    "    def __init__(self, config: Config) -> None:\n",
    "        super().__init__()\n",
    "        self.n = config.code.n\n",
    "        self.syndrom_length = config.code.pc_matrix.size(0)\n",
    "        self.mamba: ModuleList = clones(EncoderLayer(config,), config.N_dec)\n",
    "        self.resize_output_length = torch.nn.Linear(self.n + self.syndrom_length, self.n)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def forward(self, magnitude, syndrome):\n",
    "        inp = torch.cat([magnitude, syndrome], -1)\n",
    "        emb = inp.unsqueeze(-1)\n",
    "        hidden = emb\n",
    "        for sublayer in self.mamba:\n",
    "            hidden: torch.Tensor = sublayer.forward(hidden)\n",
    "        hidden = emb + hidden\n",
    "        out = self.resize_output_length(hidden.squeeze(-1))\n",
    "        return (1-F.tanh(out))/2\n",
    "\n",
    "    def loss(self, z_pred, z2, y):\n",
    "        loss = F.binary_cross_entropy(\n",
    "            z_pred, sign_to_bin(torch.sign(z2)))\n",
    "        x_pred = sign_to_bin(torch.sign(bin_to_sign(F.tanh(z_pred)) * torch.sign(y)))\n",
    "        return loss, x_pred\n",
    "\n",
    "\n",
    "model = ECCM(config=config).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 09:22:55,386\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-01-10 09:22:55,580\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from ray.train import Checkpoint\n",
    "from ray import train as ray_train, tune as ray_tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ray.tune' from '/home/shyel/repositories/mamba_linear_code/.venv/lib/python3.12/site-packages/ray/tune/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 09:22:56,501\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "2025-01-10 09:22:56,938\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2025-01-10 09:22:56,938\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-01-10 09:23:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:30.28        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.3/62.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">    eta_min</th><th style=\"text-align: right;\">  gradient_clipping</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  warmup_length</th><th style=\"text-align: right;\">  warmup_lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_train_e2eed3cd</td><td>RUNNING </td><td>192.168.1.13:642836</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">3.31735e-11</td><td style=\"text-align: right;\">           2.45633 </td><td style=\"text-align: right;\">6.06737e-05</td><td style=\"text-align: right;\">             10</td><td style=\"text-align: right;\"> 0.00437244</td></tr>\n",
       "<tr><td>tune_train_6456ab2e</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">8.71791e-07</td><td style=\"text-align: right;\">           0.198339</td><td style=\"text-align: right;\">0.00251743 </td><td style=\"text-align: right;\">             10</td><td style=\"text-align: right;\"> 0.00551829</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 1/1000 [00:00<05:38,  2.95it/s]\n",
      "Training:   0%|          | 4/1000 [00:00<01:32, 10.75it/s]\n",
      "Training:   1%|          | 8/1000 [00:00<00:56, 17.63it/s]\n",
      "Training:   1%|          | 12/1000 [00:00<00:45, 21.80it/s]\n",
      "Training:   2%|▏         | 15/1000 [00:00<00:41, 23.97it/s]\n",
      "Training:   2%|▏         | 18/1000 [00:00<00:38, 25.61it/s]\n",
      "Training:   2%|▏         | 21/1000 [00:01<00:36, 26.81it/s]\n",
      "Training:   2%|▎         | 25/1000 [00:01<00:34, 27.97it/s]\n",
      "Training:   3%|▎         | 28/1000 [00:01<00:34, 28.52it/s]\n",
      "Training:   3%|▎         | 32/1000 [00:01<00:33, 29.01it/s]\n",
      "Training:   4%|▎         | 35/1000 [00:01<00:32, 29.26it/s]\n",
      "Training:   4%|▍         | 38/1000 [00:01<00:32, 29.41it/s]\n",
      "Training:   4%|▍         | 42/1000 [00:01<00:32, 29.64it/s]\n",
      "Training:   5%|▍         | 46/1000 [00:01<00:31, 29.84it/s]\n",
      "Training:   5%|▍         | 49/1000 [00:01<00:31, 29.83it/s]\n",
      "Training:   5%|▌         | 53/1000 [00:02<00:31, 29.91it/s]\n",
      "Training:   6%|▌         | 56/1000 [00:02<00:31, 29.70it/s]\n",
      "Training:   6%|▌         | 60/1000 [00:02<00:31, 29.95it/s]\n",
      "Training:   6%|▋         | 63/1000 [00:02<00:31, 29.92it/s]\n",
      "Training:   7%|▋         | 67/1000 [00:02<00:31, 30.05it/s]\n",
      "Training:   7%|▋         | 71/1000 [00:02<00:30, 30.08it/s]\n",
      "Training:   8%|▊         | 75/1000 [00:02<00:30, 30.15it/s]\n",
      "Training:   8%|▊         | 79/1000 [00:02<00:30, 30.08it/s]\n",
      "Training:   8%|▊         | 83/1000 [00:03<00:30, 30.06it/s]\n",
      "Training:   9%|▊         | 87/1000 [00:03<00:30, 29.84it/s]\n",
      "Training:   9%|▉         | 91/1000 [00:03<00:30, 29.92it/s]\n",
      "Training:   9%|▉         | 94/1000 [00:03<00:30, 29.88it/s]\n",
      "Training:  10%|▉         | 97/1000 [00:03<00:30, 29.81it/s]\n",
      "Training:  10%|█         | 100/1000 [00:03<00:30, 29.83it/s]\n",
      "Training:  10%|█         | 103/1000 [00:03<00:30, 29.86it/s]\n",
      "Training:  11%|█         | 107/1000 [00:03<00:29, 29.93it/s]\n",
      "Training:  11%|█         | 111/1000 [00:04<00:29, 29.94it/s]\n",
      "Training:  11%|█▏        | 114/1000 [00:04<00:29, 29.93it/s]\n",
      "Training:  12%|█▏        | 117/1000 [00:04<00:29, 29.93it/s]\n",
      "Training:  12%|█▏        | 120/1000 [00:04<00:29, 29.79it/s]\n",
      "Training:  12%|█▏        | 123/1000 [00:04<00:29, 29.83it/s]\n",
      "Training:  13%|█▎        | 127/1000 [00:04<00:29, 29.88it/s]\n",
      "Training:  13%|█▎        | 130/1000 [00:04<00:29, 29.89it/s]\n",
      "Training:  13%|█▎        | 133/1000 [00:04<00:29, 29.88it/s]\n",
      "Training:  14%|█▎        | 136/1000 [00:04<00:29, 29.46it/s]\n",
      "Training:  14%|█▍        | 140/1000 [00:04<00:28, 29.92it/s]\n",
      "Training:  14%|█▍        | 144/1000 [00:05<00:27, 30.74it/s]\n",
      "Training:  15%|█▍        | 148/1000 [00:05<00:27, 31.09it/s]\n",
      "Training:  15%|█▌        | 152/1000 [00:05<00:27, 30.72it/s]\n",
      "Training:  16%|█▌        | 156/1000 [00:05<00:27, 30.46it/s]\n",
      "Training:  16%|█▌        | 160/1000 [00:05<00:27, 30.28it/s]\n",
      "Training:  16%|█▋        | 164/1000 [00:05<00:27, 30.17it/s]\n",
      "Training:  17%|█▋        | 168/1000 [00:05<00:27, 30.10it/s]\n",
      "Training:  17%|█▋        | 172/1000 [00:06<00:27, 30.05it/s]\n",
      "Training:  18%|█▊        | 176/1000 [00:06<00:27, 30.03it/s]\n",
      "Training:  18%|█▊        | 180/1000 [00:06<00:27, 29.96it/s]\n",
      "Training:  18%|█▊        | 184/1000 [00:06<00:27, 30.04it/s]\n",
      "Training:  19%|█▉        | 188/1000 [00:06<00:27, 30.03it/s]\n",
      "Training:  19%|█▉        | 192/1000 [00:06<00:26, 29.95it/s]\n",
      "Training:  20%|█▉        | 196/1000 [00:06<00:26, 30.01it/s]\n",
      "Training:  20%|██        | 200/1000 [00:06<00:26, 29.88it/s]\n",
      "Training:  20%|██        | 204/1000 [00:07<00:26, 29.99it/s]\n",
      "Training:  21%|██        | 207/1000 [00:07<00:26, 29.98it/s]\n",
      "Training:  21%|██        | 211/1000 [00:07<00:26, 30.12it/s]\n",
      "Training:  22%|██▏       | 215/1000 [00:07<00:26, 30.10it/s]\n",
      "Training:  22%|██▏       | 219/1000 [00:07<00:25, 30.10it/s]\n",
      "Training:  22%|██▏       | 223/1000 [00:07<00:25, 30.09it/s]\n",
      "Training:  23%|██▎       | 227/1000 [00:07<00:25, 29.96it/s]\n",
      "Training:  23%|██▎       | 231/1000 [00:08<00:25, 30.08it/s]\n",
      "Training:  24%|██▎       | 235/1000 [00:08<00:25, 30.17it/s]\n",
      "Training:  24%|██▍       | 239/1000 [00:08<00:25, 30.09it/s]\n",
      "Training:  24%|██▍       | 243/1000 [00:08<00:25, 30.09it/s]\n",
      "Training:  25%|██▍       | 247/1000 [00:08<00:24, 30.15it/s]\n",
      "Training:  25%|██▌       | 251/1000 [00:08<00:24, 30.13it/s]\n",
      "Training:  26%|██▌       | 255/1000 [00:08<00:24, 30.14it/s]\n",
      "Training:  26%|██▌       | 259/1000 [00:08<00:24, 30.08it/s]\n",
      "Training:  26%|██▋       | 263/1000 [00:09<00:24, 30.01it/s]\n",
      "Training:  27%|██▋       | 267/1000 [00:09<00:24, 30.06it/s]\n",
      "Training:  27%|██▋       | 271/1000 [00:09<00:24, 30.05it/s]\n",
      "Training:  28%|██▊       | 275/1000 [00:09<00:24, 30.08it/s]\n",
      "Training:  28%|██▊       | 279/1000 [00:09<00:23, 30.10it/s]\n",
      "Training:  28%|██▊       | 283/1000 [00:09<00:23, 30.12it/s]\n",
      "Training:  29%|██▊       | 287/1000 [00:09<00:23, 30.05it/s]\n",
      "Training:  29%|██▉       | 291/1000 [00:09<00:23, 30.03it/s]\n",
      "Training:  30%|██▉       | 295/1000 [00:10<00:23, 30.05it/s]\n",
      "Training:  30%|██▉       | 299/1000 [00:10<00:23, 30.03it/s]\n",
      "Training:  30%|███       | 303/1000 [00:10<00:23, 30.10it/s]\n",
      "Training:  31%|███       | 307/1000 [00:10<00:23, 30.12it/s]\n",
      "Training:  31%|███       | 311/1000 [00:10<00:22, 30.15it/s]\n",
      "Training:  32%|███▏      | 315/1000 [00:10<00:22, 30.66it/s]\n",
      "Training:  32%|███▏      | 319/1000 [00:10<00:22, 30.38it/s]\n",
      "Training:  32%|███▏      | 323/1000 [00:11<00:22, 30.13it/s]\n",
      "Training:  33%|███▎      | 327/1000 [00:11<00:22, 29.71it/s]\n",
      "Training:  33%|███▎      | 330/1000 [00:11<00:23, 29.04it/s]\n",
      "Training:  33%|███▎      | 334/1000 [00:11<00:22, 29.36it/s]\n",
      "Training:  34%|███▎      | 337/1000 [00:11<00:22, 29.52it/s]\n",
      "Training:  34%|███▍      | 341/1000 [00:11<00:22, 29.77it/s]\n",
      "Training:  34%|███▍      | 345/1000 [00:11<00:21, 29.87it/s]\n",
      "Training:  35%|███▍      | 348/1000 [00:11<00:21, 29.88it/s]\n",
      "Training:  35%|███▌      | 352/1000 [00:12<00:21, 29.97it/s]\n",
      "Training:  36%|███▌      | 356/1000 [00:12<00:21, 30.10it/s]\n",
      "Training:  36%|███▌      | 360/1000 [00:12<00:21, 30.04it/s]\n",
      "Training:  36%|███▋      | 364/1000 [00:12<00:21, 30.00it/s]\n",
      "Training:  37%|███▋      | 367/1000 [00:12<00:21, 29.94it/s]\n",
      "Training:  37%|███▋      | 371/1000 [00:12<00:20, 30.10it/s]\n",
      "Training:  38%|███▊      | 375/1000 [00:12<00:20, 30.16it/s]\n",
      "Training:  38%|███▊      | 379/1000 [00:12<00:20, 30.09it/s]\n",
      "Training:  38%|███▊      | 383/1000 [00:13<00:20, 30.09it/s]\n",
      "Training:  39%|███▊      | 387/1000 [00:13<00:20, 30.04it/s]\n",
      "Training:  39%|███▉      | 391/1000 [00:13<00:19, 30.54it/s]\n",
      "Training:  40%|███▉      | 395/1000 [00:13<00:19, 30.91it/s]\n",
      "Training:  40%|███▉      | 399/1000 [00:13<00:19, 30.23it/s]\n",
      "Training:  40%|████      | 403/1000 [00:13<00:19, 30.14it/s]\n",
      "Training:  41%|████      | 407/1000 [00:13<00:19, 30.14it/s]\n",
      "Training:  41%|████      | 411/1000 [00:13<00:19, 30.15it/s]\n",
      "Training:  42%|████▏     | 415/1000 [00:14<00:19, 30.07it/s]\n",
      "Training:  42%|████▏     | 419/1000 [00:14<00:19, 30.02it/s]\n",
      "Training:  42%|████▏     | 423/1000 [00:14<00:19, 29.95it/s]\n",
      "Training:  43%|████▎     | 426/1000 [00:14<00:19, 29.83it/s]\n",
      "Training:  43%|████▎     | 430/1000 [00:14<00:19, 29.88it/s]\n",
      "Training:  43%|████▎     | 434/1000 [00:14<00:18, 30.03it/s]\n",
      "Training:  44%|████▍     | 438/1000 [00:14<00:18, 30.06it/s]\n",
      "Training:  44%|████▍     | 442/1000 [00:15<00:18, 30.10it/s]\n",
      "Training:  45%|████▍     | 446/1000 [00:15<00:18, 30.11it/s]\n",
      "Training:  45%|████▌     | 450/1000 [00:15<00:18, 30.03it/s]\n",
      "Training:  45%|████▌     | 454/1000 [00:15<00:18, 30.05it/s]\n",
      "Training:  46%|████▌     | 458/1000 [00:15<00:18, 30.10it/s]\n",
      "Training:  46%|████▌     | 462/1000 [00:15<00:17, 30.06it/s]\n",
      "Training:  47%|████▋     | 466/1000 [00:15<00:17, 30.34it/s]\n",
      "Training:  47%|████▋     | 470/1000 [00:15<00:17, 30.15it/s]\n",
      "Training:  47%|████▋     | 474/1000 [00:16<00:17, 30.17it/s]\n",
      "Training:  48%|████▊     | 478/1000 [00:16<00:17, 30.22it/s]\n",
      "Training:  48%|████▊     | 482/1000 [00:16<00:17, 30.17it/s]\n",
      "Training:  49%|████▊     | 486/1000 [00:16<00:17, 30.04it/s]\n",
      "Training:  49%|████▉     | 490/1000 [00:16<00:16, 30.05it/s]\n",
      "Training:  49%|████▉     | 494/1000 [00:16<00:16, 29.85it/s]\n",
      "Training:  50%|████▉     | 498/1000 [00:16<00:16, 29.89it/s]\n",
      "Training:  50%|█████     | 502/1000 [00:17<00:16, 30.01it/s]\n",
      "Training:  51%|█████     | 506/1000 [00:17<00:16, 30.14it/s]\n",
      "Training:  51%|█████     | 510/1000 [00:17<00:16, 29.92it/s]\n",
      "Training:  51%|█████▏    | 513/1000 [00:17<00:16, 29.88it/s]\n",
      "Training:  52%|█████▏    | 517/1000 [00:17<00:16, 30.00it/s]\n",
      "Training:  52%|█████▏    | 521/1000 [00:17<00:15, 30.04it/s]\n",
      "Training:  52%|█████▎    | 525/1000 [00:17<00:15, 29.85it/s]\n",
      "Training:  53%|█████▎    | 528/1000 [00:17<00:15, 29.87it/s]\n",
      "Training:  53%|█████▎    | 531/1000 [00:17<00:15, 29.86it/s]\n",
      "Training:  54%|█████▎    | 535/1000 [00:18<00:15, 30.03it/s]\n",
      "Training:  54%|█████▍    | 539/1000 [00:18<00:15, 30.05it/s]\n",
      "Training:  54%|█████▍    | 543/1000 [00:18<00:15, 30.05it/s]\n",
      "Training:  55%|█████▍    | 547/1000 [00:18<00:15, 29.92it/s]\n",
      "Training:  55%|█████▌    | 551/1000 [00:18<00:14, 30.01it/s]\n",
      "Training:  56%|█████▌    | 555/1000 [00:18<00:14, 30.00it/s]\n",
      "Training:  56%|█████▌    | 559/1000 [00:18<00:14, 29.95it/s]\n",
      "Training:  56%|█████▋    | 563/1000 [00:19<00:14, 29.97it/s]\n",
      "Training:  57%|█████▋    | 567/1000 [00:19<00:14, 29.98it/s]\n",
      "Training:  57%|█████▋    | 570/1000 [00:19<00:14, 29.99it/s]\n",
      "Training:  57%|█████▋    | 574/1000 [00:19<00:14, 30.03it/s]\n",
      "Training:  58%|█████▊    | 578/1000 [00:19<00:14, 30.04it/s]\n",
      "Training:  58%|█████▊    | 582/1000 [00:19<00:13, 30.04it/s]\n",
      "Training:  59%|█████▊    | 586/1000 [00:19<00:13, 31.53it/s]\n",
      "Training:  59%|█████▉    | 590/1000 [00:19<00:12, 32.02it/s]\n",
      "Training:  59%|█████▉    | 594/1000 [00:20<00:12, 31.43it/s]\n",
      "Training:  60%|█████▉    | 598/1000 [00:20<00:12, 31.02it/s]\n",
      "Training:  60%|██████    | 602/1000 [00:20<00:12, 30.66it/s]\n",
      "Training:  61%|██████    | 606/1000 [00:20<00:12, 30.46it/s]\n",
      "Training:  61%|██████    | 610/1000 [00:20<00:12, 30.37it/s]\n",
      "Training:  61%|██████▏   | 614/1000 [00:20<00:12, 30.36it/s]\n",
      "Training:  62%|██████▏   | 618/1000 [00:20<00:12, 30.26it/s]\n",
      "Training:  62%|██████▏   | 622/1000 [00:20<00:12, 30.10it/s]\n",
      "Training:  63%|██████▎   | 626/1000 [00:21<00:12, 30.03it/s]\n",
      "Training:  63%|██████▎   | 630/1000 [00:21<00:12, 29.82it/s]\n",
      "Training:  63%|██████▎   | 634/1000 [00:21<00:12, 29.88it/s]\n",
      "Training:  64%|██████▎   | 637/1000 [00:21<00:12, 29.91it/s]\n",
      "Training:  64%|██████▍   | 640/1000 [00:21<00:12, 29.92it/s]\n",
      "Training:  64%|██████▍   | 643/1000 [00:21<00:11, 29.94it/s]\n",
      "Training:  65%|██████▍   | 646/1000 [00:21<00:11, 29.95it/s]\n",
      "Training:  65%|██████▍   | 649/1000 [00:21<00:11, 29.81it/s]\n",
      "Training:  65%|██████▌   | 652/1000 [00:21<00:11, 29.85it/s]\n",
      "Training:  66%|██████▌   | 655/1000 [00:22<00:11, 29.76it/s]\n",
      "Training:  66%|██████▌   | 659/1000 [00:22<00:11, 29.85it/s]\n",
      "Training:  66%|██████▋   | 663/1000 [00:22<00:11, 29.93it/s]\n",
      "Training:  67%|██████▋   | 667/1000 [00:22<00:11, 29.95it/s]\n",
      "Training:  67%|██████▋   | 671/1000 [00:22<00:10, 30.02it/s]\n",
      "Training:  68%|██████▊   | 675/1000 [00:22<00:10, 30.04it/s]\n",
      "Training:  68%|██████▊   | 679/1000 [00:22<00:10, 29.81it/s]\n",
      "Training:  68%|██████▊   | 682/1000 [00:22<00:10, 29.84it/s]\n",
      "Training:  69%|██████▊   | 686/1000 [00:23<00:10, 29.93it/s]\n",
      "Training:  69%|██████▉   | 689/1000 [00:23<00:10, 29.87it/s]\n",
      "Training:  69%|██████▉   | 692/1000 [00:23<00:10, 29.84it/s]\n",
      "Training:  70%|██████▉   | 695/1000 [00:23<00:10, 29.85it/s]\n",
      "Training:  70%|██████▉   | 698/1000 [00:23<00:10, 29.80it/s]\n",
      "Training:  70%|███████   | 701/1000 [00:23<00:10, 29.84it/s]\n",
      "Training:  70%|███████   | 705/1000 [00:23<00:09, 29.94it/s]\n",
      "Training:  71%|███████   | 709/1000 [00:23<00:09, 29.99it/s]\n",
      "Training:  71%|███████   | 712/1000 [00:24<00:10, 28.77it/s]\n",
      "Training:  72%|███████▏  | 715/1000 [00:24<00:09, 28.80it/s]\n",
      "Training:  72%|███████▏  | 719/1000 [00:24<00:09, 29.72it/s]\n",
      "Training:  72%|███████▏  | 723/1000 [00:24<00:09, 29.85it/s]\n",
      "Training:  73%|███████▎  | 727/1000 [00:24<00:09, 29.99it/s]\n",
      "Training:  73%|███████▎  | 731/1000 [00:24<00:08, 30.05it/s]\n",
      "Training:  74%|███████▎  | 735/1000 [00:24<00:08, 30.07it/s]\n",
      "Training:  74%|███████▍  | 739/1000 [00:24<00:08, 30.02it/s]\n",
      "Training:  74%|███████▍  | 743/1000 [00:25<00:08, 30.06it/s]\n",
      "Training:  75%|███████▍  | 747/1000 [00:25<00:08, 29.96it/s]\n",
      "Training:  75%|███████▌  | 750/1000 [00:25<00:08, 29.96it/s]\n",
      "Training:  75%|███████▌  | 754/1000 [00:25<00:08, 30.00it/s]\n",
      "Training:  76%|███████▌  | 757/1000 [00:25<00:08, 29.94it/s]\n",
      "Training:  76%|███████▌  | 761/1000 [00:25<00:07, 30.00it/s]\n",
      "Training:  76%|███████▋  | 765/1000 [00:25<00:07, 29.99it/s]\n",
      "Training:  77%|███████▋  | 769/1000 [00:25<00:07, 30.05it/s]\n",
      "Training:  77%|███████▋  | 773/1000 [00:26<00:07, 29.96it/s]\n",
      "Training:  78%|███████▊  | 776/1000 [00:26<00:07, 29.96it/s]\n",
      "Training:  78%|███████▊  | 779/1000 [00:26<00:07, 29.86it/s]\n",
      "Training:  78%|███████▊  | 783/1000 [00:26<00:07, 29.93it/s]\n",
      "Training:  79%|███████▊  | 786/1000 [00:26<00:07, 29.91it/s]\n",
      "Training:  79%|███████▉  | 789/1000 [00:26<00:07, 29.91it/s]\n",
      "Training:  79%|███████▉  | 793/1000 [00:26<00:06, 30.04it/s]\n",
      "Training:  80%|███████▉  | 797/1000 [00:26<00:06, 30.04it/s]\n",
      "Training:  80%|████████  | 801/1000 [00:26<00:06, 29.96it/s]\n",
      "Training:  80%|████████  | 804/1000 [00:27<00:06, 29.91it/s]\n",
      "Training:  81%|████████  | 808/1000 [00:27<00:06, 30.04it/s]\n",
      "Training:  81%|████████  | 812/1000 [00:27<00:06, 30.02it/s]\n",
      "Training:  82%|████████▏ | 816/1000 [00:27<00:06, 30.05it/s]\n",
      "Training:  82%|████████▏ | 820/1000 [00:27<00:05, 30.10it/s]\n",
      "Training:  82%|████████▏ | 824/1000 [00:27<00:05, 30.09it/s]\n",
      "Training:  83%|████████▎ | 828/1000 [00:27<00:05, 30.10it/s]\n",
      "Training:  83%|████████▎ | 832/1000 [00:28<00:05, 30.11it/s]\n",
      "Training:  84%|████████▎ | 836/1000 [00:28<00:05, 30.03it/s]\n",
      "Training:  84%|████████▍ | 840/1000 [00:28<00:05, 29.69it/s]\n",
      "Training:  84%|████████▍ | 843/1000 [00:28<00:05, 29.75it/s]\n",
      "Training:  85%|████████▍ | 847/1000 [00:28<00:05, 29.91it/s]\n",
      "Training:  85%|████████▌ | 851/1000 [00:28<00:04, 29.97it/s]\n",
      "Training:  86%|████████▌ | 855/1000 [00:28<00:04, 30.09it/s]\n",
      "Training:  86%|████████▌ | 859/1000 [00:28<00:04, 30.07it/s]\n",
      "Training:  86%|████████▋ | 863/1000 [00:29<00:04, 30.10it/s]\n",
      "Training:  87%|████████▋ | 867/1000 [00:29<00:04, 30.09it/s]\n",
      "Training:  87%|████████▋ | 871/1000 [00:29<00:04, 30.16it/s]\n",
      "Training:  88%|████████▊ | 875/1000 [00:29<00:04, 30.11it/s]\n",
      "Training:  88%|████████▊ | 879/1000 [00:29<00:04, 30.05it/s]\n",
      "Training:  88%|████████▊ | 883/1000 [00:29<00:03, 30.03it/s]\n",
      "Training:  89%|████████▊ | 887/1000 [00:29<00:03, 30.02it/s]\n",
      "Training:  89%|████████▉ | 891/1000 [00:29<00:03, 30.06it/s]\n",
      "Training:  90%|████████▉ | 895/1000 [00:30<00:03, 30.08it/s]\n",
      "Training:  90%|████████▉ | 899/1000 [00:30<00:03, 30.13it/s]\n",
      "Training:  90%|█████████ | 903/1000 [00:30<00:03, 30.01it/s]\n",
      "Training:  91%|█████████ | 907/1000 [00:30<00:03, 29.92it/s]\n",
      "Training:  91%|█████████ | 910/1000 [00:30<00:03, 29.92it/s]\n",
      "Training:  91%|█████████▏| 914/1000 [00:30<00:02, 29.98it/s]\n",
      "Training:  92%|█████████▏| 917/1000 [00:30<00:02, 29.88it/s]\n",
      "Training:  92%|█████████▏| 921/1000 [00:30<00:02, 30.36it/s]\n",
      "Training:  92%|█████████▎| 925/1000 [00:31<00:02, 29.26it/s]\n",
      "Training:  93%|█████████▎| 928/1000 [00:31<00:02, 29.01it/s]\n",
      "Training:  93%|█████████▎| 931/1000 [00:31<00:02, 28.82it/s]\n",
      "Training:  93%|█████████▎| 934/1000 [00:31<00:02, 28.06it/s]\n",
      "Training:  94%|█████████▎| 937/1000 [00:31<00:02, 27.43it/s]\n",
      "Training:  94%|█████████▍| 940/1000 [00:31<00:02, 27.57it/s]\n",
      "Training:  94%|█████████▍| 943/1000 [00:31<00:02, 28.18it/s]\n",
      "Training:  95%|█████████▍| 946/1000 [00:31<00:01, 28.63it/s]\n",
      "Training:  95%|█████████▍| 949/1000 [00:31<00:01, 28.85it/s]\n",
      "Training:  95%|█████████▌| 953/1000 [00:32<00:01, 29.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, LR, config: Config):\n",
    "    model.train()\n",
    "    cum_loss = cum_ber = cum_fer = cum_samples = cum_loss = 0.\n",
    "    t = time.time()\n",
    "    batch_idx = 0\n",
    "    for m, x, z, y, magnitude, syndrome in tqdm(train_loader, position=0, leave=True, desc=\"Training\"):\n",
    "        z_mul = (y * bin_to_sign(x)) # x = 1, y = -1 => z_mul = -1\n",
    "        z_pred = model(magnitude.to(device), syndrome.to(device))\n",
    "        loss, x_pred = model.loss(z_pred, z_mul.to(device), y.to(device))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.gradient_clipping)\n",
    "        optimizer.step()\n",
    "        ###\n",
    "        ber = BER(x_pred, x.to(device))\n",
    "        fer = FER(x_pred, x.to(device))\n",
    "\n",
    "        cum_loss += loss.item() * x.shape[0]\n",
    "        cum_ber += ber * x.shape[0]\n",
    "        cum_fer += fer * x.shape[0]\n",
    "        cum_samples += x.shape[0]\n",
    "        if batch_idx == len(train_loader) - 1:\n",
    "            logging.info(\n",
    "                f'Training epoch {epoch}, Batch {batch_idx + 1}/{len(train_loader)}: LR={LR:.2e}, Loss={cum_loss / cum_samples:.2e} BER={cum_ber / cum_samples:.2e} FER={cum_fer / cum_samples:.2e}')\n",
    "        batch_idx += 1\n",
    "    logging.info(f'Epoch {epoch} Train Time {time.time() - t}s\\n')\n",
    "    return cum_loss / cum_samples, cum_ber / cum_samples, cum_fer / cum_samples\n",
    "\n",
    "def test(model, device, test_loader_list, EbNo_range_test, min_FER=100):\n",
    "    model.eval()\n",
    "    t = time.time()\n",
    "    results = {}\n",
    "    with torch.no_grad():\n",
    "        for ii, test_loader in enumerate(test_loader_list):\n",
    "            test_loss = test_ber = test_fer = cum_count = 0.\n",
    "            for m, x, z, y, magnitude, syndrome in tqdm(test_loader, position=0, leave=True, desc=\"Testing\"):\n",
    "                z_mul = (y * bin_to_sign(x))\n",
    "                z_pred = model(magnitude.to(device), syndrome.to(device))\n",
    "                loss, x_pred = model.loss(z_pred, z_mul.to(device), y.to(device))\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                test_ber += BER(x_pred, x.to(device))\n",
    "                test_fer += FER(x_pred, x.to(device))\n",
    "            ln_ber = -np.log(test_ber)\n",
    "            logging.info(f'Test EbN0={EbNo_range_test[ii]}, BER={test_ber:.2e} -ln(BER)={ln_ber:.2e}')\n",
    "            results[f\"BER_{EbNo_range_test[ii]}\"] = test_ber\n",
    "    return results\n",
    "\n",
    "def create_dataset(args: Config,):\n",
    "    code = args.code\n",
    "    #################################\n",
    "    EbNo_range_test = range(0, 10)\n",
    "    EbNo_range_train = range(2, 8)\n",
    "    std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
    "    std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
    "    train_dataloader = DataLoader(ECC_Dataset(code, std_train, len=args.batch_size * 1000, zero_cw=False), batch_size=int(args.batch_size),\n",
    "                                  shuffle=True, num_workers=args.workers)\n",
    "    test_dataloader_list = [DataLoader(ECC_Dataset(code, [std_test[ii]], len=int(args.test_batch_size), zero_cw=False),\n",
    "                                       batch_size=int(args.test_batch_size), shuffle=False, num_workers=args.workers) for ii in range(len(std_test))]\n",
    "    #################################\n",
    "    return train_dataloader, test_dataloader_list, EbNo_range_train, EbNo_range_test\n",
    "\n",
    "\n",
    "def epoch_callback(args: Config, epoch, loss, model, optimizer, scheduler,):\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), os.path.join(args.path, 'best_model'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(args.path, 'optimizer_checkpoint'))\n",
    "        torch.save(scheduler.state_dict(), os.path.join(args.path, 'scheduler_checkpoint'))\n",
    "\n",
    "def test_callback(args: Config, epoch, loss, test_results, model, optimizer, scheduler,):\n",
    "    pass\n",
    "\n",
    "def test_callback_tune(args: Config, epoch, loss, test_results, model, optimizer, scheduler,):\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        torch.save(model.state_dict(), os.path.join(temp_checkpoint_dir, 'model.pth'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(temp_checkpoint_dir, 'optimizer.pth'))\n",
    "        torch.save(scheduler.state_dict(), os.path.join(temp_checkpoint_dir, 'schedurel.pyh'))\n",
    "        checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "        ray_train.report(test_results, checkpoint=checkpoint)\n",
    "\n",
    "def train_model(args: Config, model: torch.nn.Module, epoch_callback=epoch_callback, test_callback=None):\n",
    "    initial_lr = args.warmup_lr\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    optimizer = Adam(model.parameters(), lr=args.warmup_lr)\n",
    "\n",
    "    # model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
    "    # optimizer.load_state_dict(torch.load(os.path.join(config.path, 'optimizer_checkpoint')))\n",
    "    train_dataloader, test_dataloader_list, _, EbNo_range_test =  create_dataset(args)\n",
    "    epoch = 0\n",
    "    loss = 0\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(1,args.warmup_length + 1):\n",
    "        loss, ber, fer = train(model, device, train_dataloader, optimizer,\n",
    "                               epoch, LR=initial_lr, config=args)\n",
    "        # if loss < best_loss:\n",
    "        #     best_loss = loss\n",
    "        #     torch.save(model.state_dict(), os.path.join(args.path, 'best_model'))\n",
    "    results = test(model, device, test_dataloader_list, EbNo_range_test)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=1000, eta_min=args.eta_min)\n",
    "    if test_callback is not None:\n",
    "        test_callback(args, args.warmup_length, loss, results, model, optimizer, scheduler)\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = args.lr\n",
    "    # scheduler.load_state_dict(torch.load(os.path.join(config.path, 'scheduler_checkpoint')))\n",
    "\n",
    "    snr_step = 0\n",
    "    for epoch in range(args.warmup_length + 1, args.epochs + 1):\n",
    "        # if best_loss < 2e-2:\n",
    "        #     print(\"snr_step: \", snr_step)\n",
    "        #     snr_step += 3\n",
    "        #     best_loss = float('inf')\n",
    "        #     EbNo_range_train = range(5-snr_step, 8)\n",
    "        #     std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
    "        #     train_dataloader = DataLoader(ECC_Dataset(code, std_train, len=args.batch_size * 1000, zero_cw=False), batch_size=int(args.batch_size),\n",
    "        #                             shuffle=True, num_workers=args.workers)\n",
    "        loss, ber, fer = train(model, device, train_dataloader, optimizer,\n",
    "                               epoch, LR=scheduler.get_last_lr()[0], config=args)\n",
    "        scheduler.step()\n",
    "        if epoch_callback is not None:\n",
    "            epoch_callback(args, epoch, loss, model, optimizer, scheduler)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            results = test(model, device, test_dataloader_list, EbNo_range_test)\n",
    "            if test_callback is not None:\n",
    "                test_callback(args, epoch, loss, results, model, optimizer, scheduler)\n",
    "\n",
    "    return model\n",
    "\n",
    "def tune_train(tuning_parameters):\n",
    "    config = Config(\n",
    "        code=example_code,\n",
    "        d_model=128, # example_code.n + H.shape[0],\n",
    "        path=OUTPUT_PATH,\n",
    "        N_dec=8,\n",
    "        warmup_lr=tuning_parameters[\"warmup_lr\"],\n",
    "        warmup_length=tuning_parameters[\"warmup_length\"],\n",
    "        lr=tuning_parameters[\"lr\"],\n",
    "        epochs=200,\n",
    "        eta_min=tuning_parameters[\"eta_min\"],\n",
    "        batch_size=tuning_parameters[\"batch_size\"],\n",
    "        gradient_clipping=tuning_parameters[\"gradient_clipping\"]\n",
    "    )\n",
    "    model = ECCM(config=config).to(\"cuda\")\n",
    "    train_model(config, model, epoch_callback=None, test_callback=test_callback_tune)\n",
    "\n",
    "search_space = {\n",
    "    \"warmup_lr\": ray_tune.loguniform(1e-6, 1e-2),\n",
    "    \"warmup_length\": ray_tune.choice([0, 5, 10, 15, 20]),\n",
    "    \"lr\": ray_tune.loguniform(1e-5, 1e-1),\n",
    "    \"eta_min\": ray_tune.loguniform(1e-12, 1e-4),\n",
    "    \"batch_size\": ray_tune.choice([16,32,64,128,256,512,1024]),\n",
    "    \"gradient_clipping\": ray_tune.loguniform(0.01,10.0),\n",
    "}\n",
    "\n",
    "tune_algo = HyperOptSearch(\n",
    "    metric=\"BER_6\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "tune_sched = ASHAScheduler(\n",
    "    metric=\"BER_6\",\n",
    "    mode=\"min\",\n",
    "    grace_period=10\n",
    ")\n",
    "\n",
    "results = ray_tune.run(\n",
    "    tune_train,\n",
    "    config=search_space,\n",
    "    search_alg=tune_algo,\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    num_samples=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ECCM(config=config)\n",
    "model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import bin_to_sign\n",
    "import numpy as np\n",
    "code = config.code\n",
    "# EbNo_range_test = range(0, 10)\n",
    "EbNo_range_test = [2,3,4,5,6,7,8,9,10]\n",
    "std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
    "test_dataloader_list = [DataLoader(ECC_Dataset(code, [std_test[ii]], len=int(config.test_batch_size), zero_cw=False),\n",
    "                                       batch_size=int(config.test_batch_size), shuffle=False, num_workers=config.workers) for ii in range(len(std_test))]\n",
    "model.eval()\n",
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    for ii, test_loader in enumerate(test_dataloader_list):\n",
    "        test_loss = test_ber = test_fer = cum_count = 0.\n",
    "        for m, x, z, y, magnitude, syndrome in tqdm(test_loader, position=0, leave=True, desc=\"Testing\"):\n",
    "            z_mul = (y * bin_to_sign(x))\n",
    "            z_pred = model(y.to(device), syndrome.to(device))\n",
    "            loss, x_pred = model.loss(z_pred, z_mul.to(device), y.to(device))\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            test_ber += BER(x_pred, x.to(device))\n",
    "            test_fer += FER(x_pred, x.to(device))\n",
    "            # break\n",
    "        ln_ber = -np.log(test_ber)\n",
    "        logging.info(f'Test EbN0={EbNo_range_test[ii]}, BER={test_ber:.2e} -ln(BER)={ln_ber:.2e} loss={loss:.2e}')\n",
    "        # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "z_pred = model(y.to('cuda'), syndrome.to('cuda'))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bin_to_sign(x[0]))\n",
    "plt.plot(bin_to_sign(x_pred[0].cpu().detach().numpy()))\n",
    "plt.plot(y[0])\n",
    "# plt.plot(z_mul[0])\n",
    "plt.figure()\n",
    "plt.plot(sign_to_bin(torch.sign(z_mul[0])))\n",
    "plt.plot(z_pred[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.binary_cross_entropy(z_pred[0].cpu().detach(), sign_to_bin(torch.sign(z_mul[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred = model(y.to('cuda'), syndrome.to('cuda'))\n",
    "print(\"z_mul\", z_mul)\n",
    "print(\"z_pred\", z_pred)\n",
    "loss, x_pred = model.loss(-z_pred, z_mul.to('cuda'), y.to('cuda'))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas:\n",
    "# Bi-directional\n",
    "# Load and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

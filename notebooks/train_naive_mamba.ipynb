{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/workspaces/MambaLinearCode\")\n",
    "os.chdir(\"/workspaces/MambaLinearCode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDPC_N49_K24.alist\n"
     ]
    }
   ],
   "source": [
    "from configuration import Code, Config\n",
    "from dataset import get_generator_and_parity\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "\n",
    "def code_from_hint(hint,):\n",
    "    code_files = os.listdir(CODES_PATH)\n",
    "    code_files = [f for f in code_files if hint in f][0]\n",
    "    print(code_files)\n",
    "    code_n = int(code_files.split('_')[1][1:])\n",
    "    code_k = int(code_files.split('_')[-1][1:].split('.')[0])\n",
    "    code_type = code_files.split('_')[0]\n",
    "    code = Code(code_n, code_k, code_type)\n",
    "    return code\n",
    "\n",
    "OUTPUT_PATH = \".output/\"\n",
    "CODES_PATH = \"codes/\"\n",
    "example_code = code_from_hint(\"LDPC_N49_K24\")\n",
    "G,H = get_generator_and_parity(example_code, standard_form=True)\n",
    "example_code.generator_matrix = torch.from_numpy(G).transpose(0,1).long()\n",
    "example_code.pc_matrix = torch.from_numpy(H).long()\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "config = Config(\n",
    "    code=example_code,\n",
    "    d_model=32,\n",
    "    d_state=64,\n",
    "    path=OUTPUT_PATH,\n",
    "    N_dec=8,\n",
    "    warmup_lr=1.0e-4,\n",
    "    lr=1.0e-4,\n",
    "    epochs=1000\n",
    ")\n",
    "\n",
    "handlers = [\n",
    "        logging.FileHandler(os.path.join(OUTPUT_PATH, 'logging.txt')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s',\n",
    "                    handlers=handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm import Mamba\n",
    "from dataset import EbN0_to_std, ECC_Dataset, train, test, sign_to_bin\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, LayerNorm\n",
    "import copy\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def build_mask(code):\n",
    "    mask_size = code.n + code.pc_matrix.size(0)\n",
    "    mask = torch.eye(mask_size, mask_size)\n",
    "    for ii in range(code.pc_matrix.size(0)):\n",
    "        idx = torch.where(code.pc_matrix[ii] > 0)[0]\n",
    "        for jj in idx:\n",
    "            for kk in idx:\n",
    "                if jj != kk:\n",
    "                    mask[jj, kk] += 1\n",
    "                    mask[kk, jj] += 1\n",
    "                    mask[code.n + ii, jj] += 1\n",
    "                    mask[jj, code.n + ii] += 1\n",
    "    src_mask = (mask > 0)\n",
    "    return src_mask\n",
    "\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, config: Config, length) -> None:\n",
    "        super().__init__()\n",
    "        self.mamba = Mamba(\n",
    "            d_model=config.d_model,\n",
    "            d_state=config.d_state\n",
    "        )\n",
    "        self.norm = LayerNorm((length, config.d_model))\n",
    "        self.n = config.code.n\n",
    "        self.pc_checks = config.code.pc_matrix.size(0)\n",
    "        self.register_buffer('pc_mask', build_mask(config.code))\n",
    "        self.in_resize = torch.nn.Linear(config.d_model, self.n+self.pc_checks)\n",
    "        self.in_reset_size = torch.nn.Linear(self.n + self.pc_checks, config.d_model)\n",
    "        self.out_resize = torch.nn.Linear(config.d_model, self.n+self.pc_checks)\n",
    "        self.out_reset_size = torch.nn.Linear(self.n + self.pc_checks, config.d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.in_resize(x)\n",
    "        h = h * self.pc_mask[0,0]\n",
    "        h = self.in_reset_size(h)\n",
    "        h *= x\n",
    "        o1 = self.mamba.forward(h)\n",
    "        o2 = torch.flip(self.mamba.forward(torch.flip(h,[1])),[1])\n",
    "        o = o1+o2\n",
    "        o = self.out_resize(o)\n",
    "        o = o * self.pc_mask\n",
    "        o = self.out_reset_size(o)\n",
    "        o *= x\n",
    "        return self.norm(F.tanh(x))\n",
    "\n",
    "class ECCM(torch.nn.Module):\n",
    "    def __init__(self, config: Config) -> None:\n",
    "        super().__init__()\n",
    "        self.n = config.code.n\n",
    "        self.pc_checks = config.code.pc_matrix.size(0)\n",
    "        self.src_embed = torch.nn.Parameter(torch.ones(\n",
    "            (self.n + self.pc_checks, config.d_model)))\n",
    "        self.resize_output_dim = torch.nn.Linear(config.d_model, 1)\n",
    "        self.resize_output_length = torch.nn.Linear(self.n + self.pc_checks, self.n)\n",
    "        self.norm_output = LayerNorm((self.n,))\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "        \n",
    "        self.mamba: ModuleList = clones(EncoderLayer(config, (self.n + self.pc_checks)), config.N_dec)\n",
    "    \n",
    "    def forward(self, magnitude, syndrome):\n",
    "        emb = torch.cat([magnitude, syndrome], -1).unsqueeze(-1)\n",
    "        out: torch.Tensor = self.src_embed.unsqueeze(0) * emb\n",
    "        for sublayer in self.mamba:\n",
    "            out: torch.Tensor = sublayer.forward(out) # self.n+self.syndrom_length, d_model\n",
    "        \n",
    "        out: torch.Tensor = self.resize_output_length(out.swapaxes(-2,-1))\n",
    "        out: torch.Tensor = self.resize_output_dim(out.swapaxes(-2,-1))\n",
    "        out: torch.Tensor = out.squeeze(-1)\n",
    "        return self.norm_output(F.tanh(out))\n",
    "\n",
    "    def loss(self, z_pred, z2, y):\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            z_pred, sign_to_bin(torch.sign(z2)))\n",
    "        x_pred = sign_to_bin(torch.sign(-z_pred * torch.sign(y)))\n",
    "        return loss, x_pred\n",
    "model = ECCM(config=config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.68it/s]Training epoch 1, Batch 1000/1000: LR=1.00e-04, Loss=7.45e-01 BER=6.78e-01 FER=1.00e+00\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.53it/s]\n",
      "Epoch 1 Train Time 73.93021821975708s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:13<00:00, 12.62it/s]Training epoch 2, Batch 1000/1000: LR=1.00e-04, Loss=6.73e-01 BER=4.75e-01 FER=1.00e+00\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.63it/s]\n",
      "Epoch 2 Train Time 73.36011147499084s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.45it/s]Training epoch 3, Batch 1000/1000: LR=1.00e-04, Loss=5.96e-01 BER=2.66e-01 FER=1.00e+00\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.50it/s]\n",
      "Epoch 3 Train Time 74.08665418624878s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:12<00:00, 14.90it/s]Training epoch 4, Batch 1000/1000: LR=1.00e-04, Loss=5.22e-01 BER=2.35e-01 FER=1.00e+00\n",
      "Training: 100%|██████████| 1000/1000 [01:12<00:00, 13.79it/s]\n",
      "Epoch 4 Train Time 72.53195118904114s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.94it/s]Training epoch 5, Batch 1000/1000: LR=1.00e-04, Loss=4.55e-01 BER=2.06e-01 FER=1.00e+00\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.02it/s]\n",
      "Epoch 5 Train Time 66.57089686393738s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.40it/s]Training epoch 6, Batch 1000/1000: LR=1.00e-04, Loss=3.99e-01 BER=1.36e-01 FER=9.93e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.25it/s]\n",
      "Epoch 6 Train Time 65.55916333198547s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.07it/s]Training epoch 7, Batch 1000/1000: LR=1.00e-04, Loss=3.53e-01 BER=4.87e-02 FER=6.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.27it/s]\n",
      "Epoch 7 Train Time 65.47681021690369s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.18it/s]Training epoch 8, Batch 1000/1000: LR=1.00e-04, Loss=3.14e-01 BER=4.24e-02 FER=5.92e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.12it/s]\n",
      "Epoch 8 Train Time 66.13916540145874s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.38it/s]Training epoch 9, Batch 1000/1000: LR=1.00e-04, Loss=2.82e-01 BER=4.19e-02 FER=5.91e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.03it/s]\n",
      "Epoch 9 Train Time 66.53188252449036s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 13.27it/s]Training epoch 10, Batch 1000/1000: LR=1.00e-04, Loss=2.53e-01 BER=4.06e-02 FER=5.86e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.79it/s]\n",
      "Epoch 10 Train Time 67.59968900680542s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.04it/s]Training epoch 11, Batch 1000/1000: LR=1.00e-04, Loss=2.29e-01 BER=4.02e-02 FER=5.87e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.93it/s]\n",
      "Epoch 11 Train Time 66.99233102798462s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:06<00:00, 14.34it/s]Training epoch 12, Batch 1000/1000: LR=1.00e-04, Loss=2.09e-01 BER=3.97e-02 FER=5.83e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.02it/s]\n",
      "Epoch 12 Train Time 66.58210468292236s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:16<00:00, 12.37it/s]Training epoch 13, Batch 1000/1000: LR=1.00e-04, Loss=1.92e-01 BER=3.92e-02 FER=5.81e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.07it/s]\n",
      "Epoch 13 Train Time 76.53096151351929s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.47it/s]Training epoch 14, Batch 1000/1000: LR=1.00e-04, Loss=1.78e-01 BER=3.91e-02 FER=5.84e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 14 Train Time 75.60307693481445s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.74it/s]Training epoch 15, Batch 1000/1000: LR=1.00e-04, Loss=1.66e-01 BER=3.90e-02 FER=5.81e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 15 Train Time 75.70820689201355s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 12.85it/s]Training epoch 16, Batch 1000/1000: LR=9.99e-05, Loss=1.55e-01 BER=3.88e-02 FER=5.80e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.94it/s]\n",
      "Epoch 16 Train Time 77.2602596282959s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.17it/s]Training epoch 17, Batch 1000/1000: LR=9.99e-05, Loss=1.46e-01 BER=3.85e-02 FER=5.78e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 17 Train Time 76.06109881401062s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:13<00:00, 13.33it/s]Training epoch 18, Batch 1000/1000: LR=9.99e-05, Loss=1.38e-01 BER=3.83e-02 FER=5.77e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.53it/s]\n",
      "Epoch 18 Train Time 73.91606211662292s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.61it/s]Training epoch 19, Batch 1000/1000: LR=9.99e-05, Loss=1.32e-01 BER=3.82e-02 FER=5.76e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.30it/s]\n",
      "Epoch 19 Train Time 75.17089033126831s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.76it/s]Training epoch 20, Batch 1000/1000: LR=9.99e-05, Loss=1.27e-01 BER=3.86e-02 FER=5.78e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.37it/s]\n",
      "Epoch 20 Train Time 74.77138137817383s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.90it/s]Training epoch 21, Batch 1000/1000: LR=9.99e-05, Loss=1.22e-01 BER=3.82e-02 FER=5.75e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 21 Train Time 75.2550253868103s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.91it/s]Training epoch 22, Batch 1000/1000: LR=9.99e-05, Loss=1.18e-01 BER=3.83e-02 FER=5.76e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 22 Train Time 75.7604022026062s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.83it/s]Training epoch 23, Batch 1000/1000: LR=9.99e-05, Loss=1.15e-01 BER=3.85e-02 FER=5.76e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.51it/s]\n",
      "Epoch 23 Train Time 74.00066637992859s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.72it/s]Training epoch 24, Batch 1000/1000: LR=9.99e-05, Loss=1.11e-01 BER=3.80e-02 FER=5.73e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.39it/s]\n",
      "Epoch 24 Train Time 74.67538976669312s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:14<00:00, 13.77it/s]Training epoch 25, Batch 1000/1000: LR=9.99e-05, Loss=1.08e-01 BER=3.81e-02 FER=5.73e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.31it/s]\n",
      "Epoch 25 Train Time 75.13243532180786s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 11.49it/s]Training epoch 26, Batch 1000/1000: LR=9.98e-05, Loss=1.05e-01 BER=3.78e-02 FER=5.71e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.44it/s]\n",
      "Epoch 26 Train Time 74.4203941822052s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:14<00:00, 13.31it/s]Training epoch 27, Batch 1000/1000: LR=9.98e-05, Loss=1.03e-01 BER=3.77e-02 FER=5.73e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.34it/s]\n",
      "Epoch 27 Train Time 74.95383810997009s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.24it/s]Training epoch 28, Batch 1000/1000: LR=9.98e-05, Loss=1.02e-01 BER=3.74e-02 FER=5.70e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.36it/s]\n",
      "Epoch 28 Train Time 74.83242273330688s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.44it/s]Training epoch 29, Batch 1000/1000: LR=9.98e-05, Loss=9.94e-02 BER=3.67e-02 FER=5.65e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.50it/s]\n",
      "Epoch 29 Train Time 74.09082007408142s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 13.33it/s]Training epoch 30, Batch 1000/1000: LR=9.98e-05, Loss=9.82e-02 BER=3.64e-02 FER=5.62e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.96it/s]\n",
      "Epoch 30 Train Time 77.15864562988281s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:19<00:00, 12.48it/s]Training epoch 31, Batch 1000/1000: LR=9.98e-05, Loss=9.70e-02 BER=3.60e-02 FER=5.51e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:19<00:00, 12.55it/s]\n",
      "Epoch 31 Train Time 79.70536160469055s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:20<00:00,  8.99it/s]Training epoch 32, Batch 1000/1000: LR=9.98e-05, Loss=9.58e-02 BER=3.53e-02 FER=5.37e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.43it/s]\n",
      "Epoch 32 Train Time 80.46922159194946s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 11.47it/s]Training epoch 33, Batch 1000/1000: LR=9.98e-05, Loss=9.51e-02 BER=3.51e-02 FER=5.28e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.84it/s]\n",
      "Epoch 33 Train Time 77.86460375785828s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 12.72it/s]Training epoch 34, Batch 1000/1000: LR=9.97e-05, Loss=9.40e-02 BER=3.46e-02 FER=5.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.79it/s]\n",
      "Epoch 34 Train Time 78.1793794631958s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 12.71it/s]Training epoch 35, Batch 1000/1000: LR=9.97e-05, Loss=9.31e-02 BER=3.41e-02 FER=5.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.94it/s]\n",
      "Epoch 35 Train Time 77.27126669883728s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.03it/s]Training epoch 36, Batch 1000/1000: LR=9.97e-05, Loss=9.26e-02 BER=3.39e-02 FER=4.96e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.35it/s]\n",
      "Epoch 36 Train Time 74.88189268112183s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 12.54it/s]Training epoch 37, Batch 1000/1000: LR=9.97e-05, Loss=9.27e-02 BER=3.35e-02 FER=4.71e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.84it/s]\n",
      "Epoch 37 Train Time 77.89768719673157s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:18<00:00,  9.72it/s]Training epoch 38, Batch 1000/1000: LR=9.97e-05, Loss=9.18e-02 BER=3.28e-02 FER=4.48e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:19<00:00, 12.63it/s]\n",
      "Epoch 38 Train Time 79.18184089660645s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 12.80it/s]Training epoch 39, Batch 1000/1000: LR=9.96e-05, Loss=9.19e-02 BER=3.29e-02 FER=4.43e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.88it/s]\n",
      "Epoch 39 Train Time 77.65677285194397s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:18<00:00, 12.90it/s]Training epoch 40, Batch 1000/1000: LR=9.96e-05, Loss=9.09e-02 BER=3.24e-02 FER=4.38e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.67it/s]\n",
      "Epoch 40 Train Time 78.9050567150116s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:20<00:00, 12.00it/s]Training epoch 41, Batch 1000/1000: LR=9.96e-05, Loss=9.07e-02 BER=3.24e-02 FER=4.34e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.39it/s]\n",
      "Epoch 41 Train Time 80.69218754768372s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:19<00:00, 13.22it/s]Training epoch 42, Batch 1000/1000: LR=9.96e-05, Loss=9.05e-02 BER=3.23e-02 FER=4.29e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:19<00:00, 12.64it/s]\n",
      "Epoch 42 Train Time 79.13210868835449s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 13.74it/s]Training epoch 43, Batch 1000/1000: LR=9.96e-05, Loss=9.06e-02 BER=3.25e-02 FER=4.30e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:10<00:00, 14.14it/s]\n",
      "Epoch 43 Train Time 70.7103374004364s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.14it/s]Training epoch 44, Batch 1000/1000: LR=9.95e-05, Loss=9.00e-02 BER=3.23e-02 FER=4.27e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.94it/s]\n",
      "Epoch 44 Train Time 66.93755316734314s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.26it/s]Training epoch 45, Batch 1000/1000: LR=9.95e-05, Loss=8.97e-02 BER=3.23e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.25it/s]\n",
      "Epoch 45 Train Time 65.5689115524292s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.84it/s]Training epoch 46, Batch 1000/1000: LR=9.95e-05, Loss=8.94e-02 BER=3.22e-02 FER=4.26e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.08it/s]\n",
      "Epoch 46 Train Time 66.33333158493042s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 14.32it/s]Training epoch 47, Batch 1000/1000: LR=9.95e-05, Loss=8.98e-02 BER=3.23e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.77it/s]\n",
      "Epoch 47 Train Time 67.73014950752258s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.04it/s]Training epoch 48, Batch 1000/1000: LR=9.95e-05, Loss=8.90e-02 BER=3.21e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.75it/s]\n",
      "Epoch 48 Train Time 67.81142830848694s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 14.39it/s]Training epoch 49, Batch 1000/1000: LR=9.94e-05, Loss=8.94e-02 BER=3.23e-02 FER=4.26e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:10<00:00, 14.21it/s]\n",
      "Epoch 49 Train Time 70.38318943977356s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:09<00:00, 13.42it/s]Training epoch 50, Batch 1000/1000: LR=9.94e-05, Loss=8.87e-02 BER=3.21e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.47it/s]\n",
      "Epoch 50 Train Time 69.1265480518341s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 14.73it/s]Training epoch 51, Batch 1000/1000: LR=9.94e-05, Loss=8.86e-02 BER=3.21e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.53it/s]\n",
      "Epoch 51 Train Time 68.81536078453064s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.06it/s]Training epoch 52, Batch 1000/1000: LR=9.94e-05, Loss=8.87e-02 BER=3.23e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.93it/s]\n",
      "Epoch 52 Train Time 66.99076128005981s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.51it/s]Training epoch 53, Batch 1000/1000: LR=9.93e-05, Loss=8.87e-02 BER=3.23e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.15it/s]\n",
      "Epoch 53 Train Time 66.00881338119507s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:07<00:00, 13.80it/s]Training epoch 54, Batch 1000/1000: LR=9.93e-05, Loss=8.78e-02 BER=3.20e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.76it/s]\n",
      "Epoch 54 Train Time 67.75573968887329s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 13.90it/s]Training epoch 55, Batch 1000/1000: LR=9.93e-05, Loss=8.80e-02 BER=3.21e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.47it/s]\n",
      "Epoch 55 Train Time 69.11960554122925s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 13.82it/s]Training epoch 56, Batch 1000/1000: LR=9.93e-05, Loss=8.74e-02 BER=3.20e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.63it/s]\n",
      "Epoch 56 Train Time 68.36160063743591s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:18<00:00, 12.17it/s]Training epoch 57, Batch 1000/1000: LR=9.92e-05, Loss=8.79e-02 BER=3.22e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.77it/s]\n",
      "Epoch 57 Train Time 78.29063177108765s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:22<00:00, 11.86it/s]Training epoch 58, Batch 1000/1000: LR=9.92e-05, Loss=8.76e-02 BER=3.21e-02 FER=4.26e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:22<00:00, 12.08it/s]\n",
      "Epoch 58 Train Time 82.75841689109802s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:22<00:00, 12.97it/s]Training epoch 59, Batch 1000/1000: LR=9.92e-05, Loss=8.73e-02 BER=3.20e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:22<00:00, 12.10it/s]\n",
      "Epoch 59 Train Time 82.64266562461853s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:22<00:00, 12.12it/s]Training epoch 60, Batch 1000/1000: LR=9.92e-05, Loss=8.73e-02 BER=3.20e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:23<00:00, 12.04it/s]\n",
      "Epoch 60 Train Time 83.08717036247253s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:22<00:00, 11.81it/s]Training epoch 61, Batch 1000/1000: LR=9.91e-05, Loss=8.66e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:22<00:00, 12.17it/s]\n",
      "Epoch 61 Train Time 82.15732908248901s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:22<00:00, 11.81it/s]Training epoch 62, Batch 1000/1000: LR=9.91e-05, Loss=8.74e-02 BER=3.22e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:22<00:00, 12.10it/s]\n",
      "Epoch 62 Train Time 82.66953015327454s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:18<00:00, 13.14it/s]Training epoch 63, Batch 1000/1000: LR=9.91e-05, Loss=8.68e-02 BER=3.19e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.72it/s]\n",
      "Epoch 63 Train Time 78.61603569984436s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.18it/s]Training epoch 64, Batch 1000/1000: LR=9.90e-05, Loss=8.71e-02 BER=3.21e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 64 Train Time 75.88404607772827s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.18it/s]Training epoch 65, Batch 1000/1000: LR=9.90e-05, Loss=8.61e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.16it/s]\n",
      "Epoch 65 Train Time 76.0156478881836s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.23it/s]Training epoch 66, Batch 1000/1000: LR=9.90e-05, Loss=8.66e-02 BER=3.19e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 66 Train Time 75.8558759689331s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.38it/s]Training epoch 67, Batch 1000/1000: LR=9.89e-05, Loss=8.68e-02 BER=3.20e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 67 Train Time 75.85089993476868s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.10it/s]Training epoch 68, Batch 1000/1000: LR=9.89e-05, Loss=8.69e-02 BER=3.21e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 68 Train Time 75.7830638885498s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.76it/s]Training epoch 69, Batch 1000/1000: LR=9.89e-05, Loss=8.64e-02 BER=3.19e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 69 Train Time 76.00004434585571s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.23it/s]Training epoch 70, Batch 1000/1000: LR=9.88e-05, Loss=8.57e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 70 Train Time 76.10729813575745s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.69it/s]Training epoch 71, Batch 1000/1000: LR=9.88e-05, Loss=8.67e-02 BER=3.22e-02 FER=4.25e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 71 Train Time 75.84535884857178s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.94it/s]Training epoch 72, Batch 1000/1000: LR=9.88e-05, Loss=8.64e-02 BER=3.20e-02 FER=4.24e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 72 Train Time 75.7297432422638s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.90it/s]Training epoch 73, Batch 1000/1000: LR=9.87e-05, Loss=8.57e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 73 Train Time 75.93951416015625s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.38it/s]Training epoch 74, Batch 1000/1000: LR=9.87e-05, Loss=8.63e-02 BER=3.21e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 74 Train Time 76.04109597206116s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 75, Batch 1000/1000: LR=9.87e-05, Loss=8.53e-02 BER=3.16e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 75 Train Time 75.79261231422424s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.39it/s]Training epoch 76, Batch 1000/1000: LR=9.86e-05, Loss=8.56e-02 BER=3.17e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 76 Train Time 76.06607556343079s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.72it/s]Training epoch 77, Batch 1000/1000: LR=9.86e-05, Loss=8.59e-02 BER=3.19e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 77 Train Time 75.86133480072021s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.85it/s]Training epoch 78, Batch 1000/1000: LR=9.86e-05, Loss=8.55e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 78 Train Time 75.93714833259583s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.04it/s]Training epoch 79, Batch 1000/1000: LR=9.85e-05, Loss=8.56e-02 BER=3.18e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 79 Train Time 76.00132155418396s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.42it/s]Training epoch 80, Batch 1000/1000: LR=9.85e-05, Loss=8.56e-02 BER=3.19e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 80 Train Time 76.09509873390198s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.08it/s]Training epoch 81, Batch 1000/1000: LR=9.84e-05, Loss=8.53e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 81 Train Time 75.80891942977905s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.04it/s]Training epoch 82, Batch 1000/1000: LR=9.84e-05, Loss=8.59e-02 BER=3.20e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 82 Train Time 75.88206338882446s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.01it/s]Training epoch 83, Batch 1000/1000: LR=9.84e-05, Loss=8.53e-02 BER=3.18e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 83 Train Time 75.85497808456421s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.22it/s]Training epoch 84, Batch 1000/1000: LR=9.83e-05, Loss=8.48e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 84 Train Time 76.04433870315552s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.49it/s]Training epoch 85, Batch 1000/1000: LR=9.83e-05, Loss=8.53e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 85 Train Time 76.03780245780945s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.45it/s]Training epoch 86, Batch 1000/1000: LR=9.82e-05, Loss=8.57e-02 BER=3.19e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 86 Train Time 76.11534070968628s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.19it/s]Training epoch 87, Batch 1000/1000: LR=9.82e-05, Loss=8.53e-02 BER=3.19e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 87 Train Time 75.93329238891602s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.53it/s]Training epoch 88, Batch 1000/1000: LR=9.82e-05, Loss=8.51e-02 BER=3.18e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 88 Train Time 75.9126467704773s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.88it/s]Training epoch 89, Batch 1000/1000: LR=9.81e-05, Loss=8.48e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 89 Train Time 76.06099605560303s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.39it/s]Training epoch 90, Batch 1000/1000: LR=9.81e-05, Loss=8.51e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 90 Train Time 75.8875503540039s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.01it/s]Training epoch 91, Batch 1000/1000: LR=9.80e-05, Loss=8.58e-02 BER=3.22e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 91 Train Time 75.91860604286194s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.34it/s]Training epoch 92, Batch 1000/1000: LR=9.80e-05, Loss=8.47e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 92 Train Time 75.67195415496826s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.15it/s]Training epoch 93, Batch 1000/1000: LR=9.79e-05, Loss=8.47e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 93 Train Time 76.05035543441772s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.13it/s]Training epoch 94, Batch 1000/1000: LR=9.79e-05, Loss=8.49e-02 BER=3.18e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 94 Train Time 75.81416463851929s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.30it/s]Training epoch 95, Batch 1000/1000: LR=9.79e-05, Loss=8.50e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 95 Train Time 75.83733916282654s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.18it/s]Training epoch 96, Batch 1000/1000: LR=9.78e-05, Loss=8.48e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 96 Train Time 76.03758716583252s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.38it/s]Training epoch 97, Batch 1000/1000: LR=9.78e-05, Loss=8.44e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 97 Train Time 75.78320741653442s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.64it/s]Training epoch 98, Batch 1000/1000: LR=9.77e-05, Loss=8.52e-02 BER=3.18e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 98 Train Time 75.50908327102661s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.26it/s]Training epoch 99, Batch 1000/1000: LR=9.77e-05, Loss=8.49e-02 BER=3.19e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 99 Train Time 75.82108521461487s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.17it/s]Training epoch 100, Batch 1000/1000: LR=9.76e-05, Loss=8.48e-02 BER=3.18e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 100 Train Time 75.72182035446167s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.37it/s]Training epoch 101, Batch 1000/1000: LR=9.76e-05, Loss=8.42e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 101 Train Time 76.09815716743469s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.22it/s]Training epoch 102, Batch 1000/1000: LR=9.75e-05, Loss=8.44e-02 BER=3.16e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.10it/s]\n",
      "Epoch 102 Train Time 76.32095098495483s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.23it/s]Training epoch 103, Batch 1000/1000: LR=9.75e-05, Loss=8.48e-02 BER=3.18e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 103 Train Time 75.77593946456909s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.99it/s]Training epoch 104, Batch 1000/1000: LR=9.74e-05, Loss=8.45e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 104 Train Time 75.7185070514679s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.52it/s]Training epoch 105, Batch 1000/1000: LR=9.74e-05, Loss=8.47e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 105 Train Time 75.90646767616272s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.96it/s]Training epoch 106, Batch 1000/1000: LR=9.73e-05, Loss=8.44e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 106 Train Time 75.96298956871033s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.38it/s]Training epoch 107, Batch 1000/1000: LR=9.73e-05, Loss=8.41e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "Epoch 107 Train Time 76.17072892189026s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.75it/s]Training epoch 108, Batch 1000/1000: LR=9.72e-05, Loss=8.42e-02 BER=3.16e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 108 Train Time 75.92637777328491s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.93it/s]Training epoch 109, Batch 1000/1000: LR=9.72e-05, Loss=8.46e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 109 Train Time 76.03992962837219s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 110, Batch 1000/1000: LR=9.71e-05, Loss=8.43e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 110 Train Time 75.77903318405151s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 111, Batch 1000/1000: LR=9.71e-05, Loss=8.42e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 111 Train Time 75.90487551689148s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.23it/s]Training epoch 112, Batch 1000/1000: LR=9.70e-05, Loss=8.46e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 112 Train Time 75.89878749847412s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.24it/s]Training epoch 113, Batch 1000/1000: LR=9.70e-05, Loss=8.45e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 113 Train Time 76.02270483970642s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.33it/s]Training epoch 114, Batch 1000/1000: LR=9.69e-05, Loss=8.40e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 114 Train Time 75.98533797264099s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.44it/s]Training epoch 115, Batch 1000/1000: LR=9.69e-05, Loss=8.40e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 115 Train Time 75.77369284629822s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.96it/s]Training epoch 116, Batch 1000/1000: LR=9.68e-05, Loss=8.46e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 116 Train Time 75.84039855003357s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.62it/s]Training epoch 117, Batch 1000/1000: LR=9.67e-05, Loss=8.48e-02 BER=3.19e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 117 Train Time 76.04743576049805s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.99it/s]Training epoch 118, Batch 1000/1000: LR=9.67e-05, Loss=8.40e-02 BER=3.16e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 118 Train Time 75.7602128982544s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.26it/s]Training epoch 119, Batch 1000/1000: LR=9.66e-05, Loss=8.38e-02 BER=3.16e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 119 Train Time 75.64033269882202s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.11it/s]Training epoch 120, Batch 1000/1000: LR=9.66e-05, Loss=8.39e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 120 Train Time 75.86134243011475s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.93it/s]Training epoch 121, Batch 1000/1000: LR=9.65e-05, Loss=8.40e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 121 Train Time 75.96502590179443s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.07it/s]Training epoch 122, Batch 1000/1000: LR=9.65e-05, Loss=8.41e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 122 Train Time 76.06009531021118s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.07it/s]Training epoch 123, Batch 1000/1000: LR=9.64e-05, Loss=8.42e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.11it/s]\n",
      "Epoch 123 Train Time 76.2558364868164s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.61it/s]Training epoch 124, Batch 1000/1000: LR=9.64e-05, Loss=8.43e-02 BER=3.19e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 124 Train Time 76.06808614730835s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 13.47it/s]Training epoch 125, Batch 1000/1000: LR=9.63e-05, Loss=8.42e-02 BER=3.17e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.90it/s]\n",
      "Epoch 125 Train Time 77.5482006072998s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:19<00:00, 13.46it/s]Training epoch 126, Batch 1000/1000: LR=9.62e-05, Loss=8.40e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:19<00:00, 12.63it/s]\n",
      "Epoch 126 Train Time 79.1497495174408s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.52it/s]Training epoch 127, Batch 1000/1000: LR=9.62e-05, Loss=8.41e-02 BER=3.17e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 127 Train Time 75.49662399291992s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.33it/s]Training epoch 128, Batch 1000/1000: LR=9.61e-05, Loss=8.39e-02 BER=3.16e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 128 Train Time 75.27007222175598s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.07it/s]Training epoch 129, Batch 1000/1000: LR=9.61e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 129 Train Time 75.22444319725037s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.55it/s]Training epoch 130, Batch 1000/1000: LR=9.60e-05, Loss=8.41e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 130 Train Time 75.74393081665039s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.19it/s]Training epoch 131, Batch 1000/1000: LR=9.59e-05, Loss=8.41e-02 BER=3.17e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 131 Train Time 75.31098961830139s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.91it/s]Training epoch 132, Batch 1000/1000: LR=9.59e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 132 Train Time 76.06585955619812s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.17it/s]Training epoch 133, Batch 1000/1000: LR=9.58e-05, Loss=8.41e-02 BER=3.18e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "Epoch 133 Train Time 76.02704668045044s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.05it/s]Training epoch 134, Batch 1000/1000: LR=9.57e-05, Loss=8.36e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 134 Train Time 75.59068655967712s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 12.94it/s]Training epoch 135, Batch 1000/1000: LR=9.57e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.12it/s]\n",
      "Epoch 135 Train Time 76.20212984085083s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.13it/s]Training epoch 136, Batch 1000/1000: LR=9.56e-05, Loss=8.32e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 136 Train Time 75.54056525230408s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.59it/s]Training epoch 137, Batch 1000/1000: LR=9.56e-05, Loss=8.35e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 137 Train Time 75.76355791091919s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.20it/s]Training epoch 138, Batch 1000/1000: LR=9.55e-05, Loss=8.36e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 138 Train Time 75.3431465625763s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.14it/s]Training epoch 139, Batch 1000/1000: LR=9.54e-05, Loss=8.45e-02 BER=3.20e-02 FER=4.23e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 139 Train Time 75.3740291595459s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.31it/s]Training epoch 140, Batch 1000/1000: LR=9.54e-05, Loss=8.35e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 140 Train Time 75.653480052948s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.20it/s]Training epoch 141, Batch 1000/1000: LR=9.53e-05, Loss=8.40e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 141 Train Time 75.31079387664795s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:16<00:00, 13.01it/s]Training epoch 142, Batch 1000/1000: LR=9.52e-05, Loss=8.40e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.03it/s]\n",
      "Epoch 142 Train Time 76.74308633804321s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 12.87it/s]Training epoch 143, Batch 1000/1000: LR=9.52e-05, Loss=8.40e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.05it/s]\n",
      "Epoch 143 Train Time 76.63929891586304s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.42it/s]Training epoch 144, Batch 1000/1000: LR=9.51e-05, Loss=8.32e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 144 Train Time 76.12469291687012s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.14it/s]Training epoch 145, Batch 1000/1000: LR=9.50e-05, Loss=8.37e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 145 Train Time 75.55491399765015s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.06it/s]Training epoch 146, Batch 1000/1000: LR=9.50e-05, Loss=8.37e-02 BER=3.16e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 146 Train Time 75.4637680053711s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.23it/s]Training epoch 147, Batch 1000/1000: LR=9.49e-05, Loss=8.37e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 147 Train Time 75.91712141036987s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.28it/s]Training epoch 148, Batch 1000/1000: LR=9.48e-05, Loss=8.33e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "Epoch 148 Train Time 76.16473412513733s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.24it/s]Training epoch 149, Batch 1000/1000: LR=9.47e-05, Loss=8.36e-02 BER=3.16e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 149 Train Time 75.92205023765564s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.30it/s]Training epoch 150, Batch 1000/1000: LR=9.47e-05, Loss=8.30e-02 BER=3.13e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 150 Train Time 75.92418026924133s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.58it/s]Training epoch 151, Batch 1000/1000: LR=9.46e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 151 Train Time 75.63446307182312s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.94it/s]Training epoch 152, Batch 1000/1000: LR=9.45e-05, Loss=8.36e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 152 Train Time 75.84060025215149s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.25it/s]Training epoch 153, Batch 1000/1000: LR=9.45e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 153 Train Time 75.74649357795715s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.38it/s]Training epoch 154, Batch 1000/1000: LR=9.44e-05, Loss=8.34e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 154 Train Time 75.98077464103699s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.17it/s]Training epoch 155, Batch 1000/1000: LR=9.43e-05, Loss=8.37e-02 BER=3.17e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 155 Train Time 75.98318219184875s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.59it/s]Training epoch 156, Batch 1000/1000: LR=9.42e-05, Loss=8.32e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.16it/s]\n",
      "Epoch 156 Train Time 76.01737332344055s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.44it/s]Training epoch 157, Batch 1000/1000: LR=9.42e-05, Loss=8.36e-02 BER=3.17e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 157 Train Time 75.81535339355469s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.41it/s]Training epoch 158, Batch 1000/1000: LR=9.41e-05, Loss=8.39e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 158 Train Time 75.94019222259521s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 159, Batch 1000/1000: LR=9.40e-05, Loss=8.33e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 159 Train Time 75.6535439491272s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.49it/s]Training epoch 160, Batch 1000/1000: LR=9.40e-05, Loss=8.38e-02 BER=3.17e-02 FER=4.22e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 160 Train Time 75.73430848121643s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.46it/s]Training epoch 161, Batch 1000/1000: LR=9.39e-05, Loss=8.35e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 161 Train Time 75.69203615188599s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.98it/s]Training epoch 162, Batch 1000/1000: LR=9.38e-05, Loss=8.31e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "Epoch 162 Train Time 76.09239220619202s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.01it/s]Training epoch 163, Batch 1000/1000: LR=9.37e-05, Loss=8.32e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 163 Train Time 75.99556517601013s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.95it/s]Training epoch 164, Batch 1000/1000: LR=9.37e-05, Loss=8.35e-02 BER=3.16e-02 FER=4.21e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 164 Train Time 75.7506673336029s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.92it/s]Training epoch 165, Batch 1000/1000: LR=9.36e-05, Loss=8.30e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 165 Train Time 75.69190812110901s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.67it/s]Training epoch 166, Batch 1000/1000: LR=9.35e-05, Loss=8.33e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 166 Train Time 75.81613755226135s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.05it/s]Training epoch 167, Batch 1000/1000: LR=9.34e-05, Loss=8.33e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 167 Train Time 75.6068172454834s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 12.38it/s]Training epoch 168, Batch 1000/1000: LR=9.33e-05, Loss=8.33e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "Epoch 168 Train Time 76.13529109954834s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.28it/s]Training epoch 169, Batch 1000/1000: LR=9.33e-05, Loss=8.32e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 169 Train Time 75.58902192115784s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.25it/s]Training epoch 170, Batch 1000/1000: LR=9.32e-05, Loss=8.32e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 170 Train Time 75.65055465698242s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.57it/s]Training epoch 171, Batch 1000/1000: LR=9.31e-05, Loss=8.34e-02 BER=3.16e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 171 Train Time 75.35124731063843s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.35it/s]Training epoch 172, Batch 1000/1000: LR=9.30e-05, Loss=8.31e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 172 Train Time 75.36723709106445s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.28it/s]Training epoch 173, Batch 1000/1000: LR=9.29e-05, Loss=8.34e-02 BER=3.16e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 173 Train Time 75.43048644065857s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.09it/s]Training epoch 174, Batch 1000/1000: LR=9.29e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 174 Train Time 75.50207042694092s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.02it/s]Training epoch 175, Batch 1000/1000: LR=9.28e-05, Loss=8.32e-02 BER=3.16e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 175 Train Time 75.2715814113617s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.52it/s]Training epoch 176, Batch 1000/1000: LR=9.27e-05, Loss=8.30e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 176 Train Time 75.48416209220886s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.86it/s]Training epoch 177, Batch 1000/1000: LR=9.26e-05, Loss=8.33e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 177 Train Time 75.72456049919128s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.15it/s]Training epoch 178, Batch 1000/1000: LR=9.25e-05, Loss=8.38e-02 BER=3.18e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 178 Train Time 76.00547409057617s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.81it/s]Training epoch 179, Batch 1000/1000: LR=9.25e-05, Loss=8.28e-02 BER=3.13e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 179 Train Time 75.39043068885803s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.94it/s]Training epoch 180, Batch 1000/1000: LR=9.24e-05, Loss=8.38e-02 BER=3.18e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 180 Train Time 75.55634474754333s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.30it/s]Training epoch 181, Batch 1000/1000: LR=9.23e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.30it/s]\n",
      "Epoch 181 Train Time 75.21445798873901s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.57it/s]Training epoch 182, Batch 1000/1000: LR=9.22e-05, Loss=8.29e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 182 Train Time 75.27972269058228s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.48it/s]Training epoch 183, Batch 1000/1000: LR=9.21e-05, Loss=8.34e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 183 Train Time 75.5192391872406s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.20it/s]Training epoch 184, Batch 1000/1000: LR=9.20e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 184 Train Time 75.3777539730072s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.78it/s]Training epoch 185, Batch 1000/1000: LR=9.20e-05, Loss=8.27e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 185 Train Time 75.41887307167053s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:16<00:00, 13.15it/s]Training epoch 186, Batch 1000/1000: LR=9.19e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.04it/s]\n",
      "Epoch 186 Train Time 76.67813396453857s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.17it/s]Training epoch 187, Batch 1000/1000: LR=9.18e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.10it/s]\n",
      "Epoch 187 Train Time 76.32215094566345s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.12it/s]Training epoch 188, Batch 1000/1000: LR=9.17e-05, Loss=8.32e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 188 Train Time 75.67305207252502s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.60it/s]Training epoch 189, Batch 1000/1000: LR=9.16e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 189 Train Time 75.48092103004456s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.84it/s]Training epoch 190, Batch 1000/1000: LR=9.15e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 190 Train Time 75.48801970481873s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.21it/s]Training epoch 191, Batch 1000/1000: LR=9.14e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 191 Train Time 75.39884519577026s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.30it/s]Training epoch 192, Batch 1000/1000: LR=9.14e-05, Loss=8.34e-02 BER=3.16e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 192 Train Time 75.37598490715027s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.36it/s]Training epoch 193, Batch 1000/1000: LR=9.13e-05, Loss=8.27e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 193 Train Time 75.470618724823s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.62it/s]Training epoch 194, Batch 1000/1000: LR=9.12e-05, Loss=8.27e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 194 Train Time 75.2255027294159s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.17it/s]Training epoch 195, Batch 1000/1000: LR=9.11e-05, Loss=8.32e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 195 Train Time 75.6118369102478s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.51it/s]Training epoch 196, Batch 1000/1000: LR=9.10e-05, Loss=8.29e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 196 Train Time 75.78233194351196s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.08it/s]Training epoch 197, Batch 1000/1000: LR=9.09e-05, Loss=8.31e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 197 Train Time 75.65749597549438s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.54it/s]Training epoch 198, Batch 1000/1000: LR=9.08e-05, Loss=8.31e-02 BER=3.15e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 198 Train Time 75.59201526641846s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 13.38it/s]Training epoch 199, Batch 1000/1000: LR=9.07e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 199 Train Time 75.49073910713196s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.19it/s]Training epoch 200, Batch 1000/1000: LR=9.06e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 200 Train Time 75.51866126060486s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.76it/s]Training epoch 201, Batch 1000/1000: LR=9.05e-05, Loss=8.26e-02 BER=3.13e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 201 Train Time 75.38259291648865s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.05it/s]Training epoch 202, Batch 1000/1000: LR=9.05e-05, Loss=8.28e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 202 Train Time 75.39740896224976s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.35it/s]Training epoch 203, Batch 1000/1000: LR=9.04e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 203 Train Time 75.39811706542969s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.52it/s]Training epoch 204, Batch 1000/1000: LR=9.03e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 204 Train Time 75.31341361999512s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.85it/s]Training epoch 205, Batch 1000/1000: LR=9.02e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.19e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 205 Train Time 75.47098016738892s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.22it/s]Training epoch 206, Batch 1000/1000: LR=9.01e-05, Loss=8.26e-02 BER=3.13e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 206 Train Time 75.40994954109192s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.14it/s]Training epoch 207, Batch 1000/1000: LR=9.00e-05, Loss=8.29e-02 BER=3.15e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 207 Train Time 75.43733882904053s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.98it/s]Training epoch 208, Batch 1000/1000: LR=8.99e-05, Loss=8.26e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 208 Train Time 75.46511626243591s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.72it/s]Training epoch 209, Batch 1000/1000: LR=8.98e-05, Loss=8.34e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 209 Train Time 75.63181781768799s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.50it/s]Training epoch 210, Batch 1000/1000: LR=8.97e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 210 Train Time 75.42641592025757s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 211, Batch 1000/1000: LR=8.96e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 211 Train Time 75.32054543495178s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.34it/s]Training epoch 212, Batch 1000/1000: LR=8.95e-05, Loss=8.22e-02 BER=3.12e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 212 Train Time 75.4715588092804s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.65it/s]Training epoch 213, Batch 1000/1000: LR=8.94e-05, Loss=8.29e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 213 Train Time 75.45474100112915s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.68it/s]Training epoch 214, Batch 1000/1000: LR=8.93e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 214 Train Time 75.51374650001526s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.32it/s]Training epoch 215, Batch 1000/1000: LR=8.92e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.22it/s]\n",
      "Epoch 215 Train Time 75.63800096511841s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.07it/s]Training epoch 216, Batch 1000/1000: LR=8.91e-05, Loss=8.37e-02 BER=3.18e-02 FER=4.20e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 216 Train Time 75.45921540260315s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.51it/s]Training epoch 217, Batch 1000/1000: LR=8.90e-05, Loss=8.31e-02 BER=3.16e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 217 Train Time 75.38928580284119s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.10it/s]Training epoch 218, Batch 1000/1000: LR=8.89e-05, Loss=8.21e-02 BER=3.11e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 218 Train Time 75.6148476600647s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.92it/s]Training epoch 219, Batch 1000/1000: LR=8.88e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 219 Train Time 75.57979202270508s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.67it/s]Training epoch 220, Batch 1000/1000: LR=8.87e-05, Loss=8.24e-02 BER=3.12e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 220 Train Time 75.39678835868835s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.57it/s]Training epoch 221, Batch 1000/1000: LR=8.86e-05, Loss=8.28e-02 BER=3.16e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 221 Train Time 75.61295413970947s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.49it/s]Training epoch 222, Batch 1000/1000: LR=8.85e-05, Loss=8.29e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.30it/s]\n",
      "Epoch 222 Train Time 75.19407224655151s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.50it/s]Training epoch 223, Batch 1000/1000: LR=8.84e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "Epoch 223 Train Time 75.41879200935364s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.34it/s]Training epoch 224, Batch 1000/1000: LR=8.83e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "Epoch 224 Train Time 75.54735112190247s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.10it/s]Training epoch 225, Batch 1000/1000: LR=8.82e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 225 Train Time 75.82432174682617s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.24it/s]Training epoch 226, Batch 1000/1000: LR=8.81e-05, Loss=8.22e-02 BER=3.12e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 226 Train Time 75.45520520210266s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.38it/s]Training epoch 227, Batch 1000/1000: LR=8.80e-05, Loss=8.23e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.30it/s]\n",
      "Epoch 227 Train Time 75.20325040817261s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.92it/s]Training epoch 228, Batch 1000/1000: LR=8.79e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 228 Train Time 75.4610366821289s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.19it/s]Training epoch 229, Batch 1000/1000: LR=8.78e-05, Loss=8.23e-02 BER=3.12e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 229 Train Time 75.34662866592407s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.13it/s]Training epoch 230, Batch 1000/1000: LR=8.77e-05, Loss=8.31e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 230 Train Time 75.49724960327148s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.86it/s]Training epoch 231, Batch 1000/1000: LR=8.76e-05, Loss=8.27e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 231 Train Time 75.71750450134277s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.96it/s]Training epoch 232, Batch 1000/1000: LR=8.75e-05, Loss=8.29e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 232 Train Time 75.7845344543457s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.93it/s]Training epoch 233, Batch 1000/1000: LR=8.74e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.23it/s]\n",
      "Epoch 233 Train Time 75.57850432395935s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.24it/s]Training epoch 234, Batch 1000/1000: LR=8.73e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 234 Train Time 75.9115240573883s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.25it/s]Training epoch 235, Batch 1000/1000: LR=8.72e-05, Loss=8.29e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 235 Train Time 75.91932892799377s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.33it/s]Training epoch 236, Batch 1000/1000: LR=8.71e-05, Loss=8.27e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.17it/s]\n",
      "Epoch 236 Train Time 75.92274951934814s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 11.55it/s]Training epoch 237, Batch 1000/1000: LR=8.70e-05, Loss=8.25e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.82it/s]\n",
      "Epoch 237 Train Time 78.01782846450806s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:20<00:00, 12.94it/s]Training epoch 238, Batch 1000/1000: LR=8.69e-05, Loss=8.22e-02 BER=3.12e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.46it/s]\n",
      "Epoch 238 Train Time 80.27136039733887s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:19<00:00, 12.20it/s]Training epoch 239, Batch 1000/1000: LR=8.68e-05, Loss=8.25e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:19<00:00, 12.64it/s]\n",
      "Epoch 239 Train Time 79.13323664665222s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:20<00:00, 11.64it/s]Training epoch 240, Batch 1000/1000: LR=8.67e-05, Loss=8.23e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.44it/s]\n",
      "Epoch 240 Train Time 80.41661643981934s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:20<00:00, 12.13it/s]Training epoch 241, Batch 1000/1000: LR=8.66e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.37it/s]\n",
      "Epoch 241 Train Time 80.86043977737427s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:22<00:00, 12.10it/s]Training epoch 242, Batch 1000/1000: LR=8.65e-05, Loss=8.19e-02 BER=3.10e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:22<00:00, 12.09it/s]\n",
      "Epoch 242 Train Time 82.7159948348999s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:20<00:00, 12.57it/s]Training epoch 243, Batch 1000/1000: LR=8.64e-05, Loss=8.27e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:21<00:00, 12.35it/s]\n",
      "Epoch 243 Train Time 81.00341701507568s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:21<00:00, 12.01it/s]Training epoch 244, Batch 1000/1000: LR=8.63e-05, Loss=8.21e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:21<00:00, 12.31it/s]\n",
      "Epoch 244 Train Time 81.25250029563904s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:18<00:00, 12.33it/s]Training epoch 245, Batch 1000/1000: LR=8.62e-05, Loss=8.19e-02 BER=3.11e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:18<00:00, 12.68it/s]\n",
      "Epoch 245 Train Time 78.84730839729309s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 12.99it/s]Training epoch 246, Batch 1000/1000: LR=8.60e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.18e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.98it/s]\n",
      "Epoch 246 Train Time 77.04431891441345s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 11.47it/s]Training epoch 247, Batch 1000/1000: LR=8.59e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.84it/s]\n",
      "Epoch 247 Train Time 77.8751699924469s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 14.99it/s]Training epoch 248, Batch 1000/1000: LR=8.58e-05, Loss=8.25e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.36it/s]\n",
      "Epoch 248 Train Time 74.85760307312012s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.19it/s]Training epoch 249, Batch 1000/1000: LR=8.57e-05, Loss=8.27e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.94it/s]\n",
      "Epoch 249 Train Time 66.9357385635376s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 14.09it/s]Training epoch 250, Batch 1000/1000: LR=8.56e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.90it/s]\n",
      "Epoch 250 Train Time 67.1249840259552s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.41it/s]Training epoch 251, Batch 1000/1000: LR=8.55e-05, Loss=8.28e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.11it/s]\n",
      "Epoch 251 Train Time 66.19175291061401s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:06<00:00, 14.91it/s]Training epoch 252, Batch 1000/1000: LR=8.54e-05, Loss=8.30e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.99it/s]\n",
      "Epoch 252 Train Time 66.69748020172119s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.29it/s]Training epoch 253, Batch 1000/1000: LR=8.53e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.97it/s]\n",
      "Epoch 253 Train Time 66.79039573669434s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.98it/s]Training epoch 254, Batch 1000/1000: LR=8.52e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.24it/s]\n",
      "Epoch 254 Train Time 65.61539554595947s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 14.98it/s]Training epoch 255, Batch 1000/1000: LR=8.51e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.84it/s]\n",
      "Epoch 255 Train Time 67.39192748069763s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.82it/s]Training epoch 256, Batch 1000/1000: LR=8.49e-05, Loss=8.23e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.06it/s]\n",
      "Epoch 256 Train Time 66.40857648849487s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 13.61it/s]Training epoch 257, Batch 1000/1000: LR=8.48e-05, Loss=8.25e-02 BER=3.15e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:10<00:00, 14.11it/s]\n",
      "Epoch 257 Train Time 70.85748028755188s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.64it/s]Training epoch 258, Batch 1000/1000: LR=8.47e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.47it/s]\n",
      "Epoch 258 Train Time 74.23018169403076s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.85it/s]Training epoch 259, Batch 1000/1000: LR=8.46e-05, Loss=8.29e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.40it/s]\n",
      "Epoch 259 Train Time 74.60700488090515s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.72it/s]Training epoch 260, Batch 1000/1000: LR=8.45e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.45it/s]\n",
      "Epoch 260 Train Time 74.33858394622803s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:13<00:00, 13.75it/s]Training epoch 261, Batch 1000/1000: LR=8.44e-05, Loss=8.27e-02 BER=3.15e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.49it/s]\n",
      "Epoch 261 Train Time 74.13520884513855s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.01it/s]Training epoch 262, Batch 1000/1000: LR=8.43e-05, Loss=8.25e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.59it/s]\n",
      "Epoch 262 Train Time 73.58436965942383s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 15.30it/s]Training epoch 263, Batch 1000/1000: LR=8.42e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.57it/s]\n",
      "Epoch 263 Train Time 73.71871948242188s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.23it/s]Training epoch 264, Batch 1000/1000: LR=8.40e-05, Loss=8.20e-02 BER=3.12e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.05it/s]\n",
      "Epoch 264 Train Time 66.46346926689148s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.74it/s]Training epoch 265, Batch 1000/1000: LR=8.39e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.18it/s]\n",
      "Epoch 265 Train Time 65.88524913787842s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.14it/s]Training epoch 266, Batch 1000/1000: LR=8.38e-05, Loss=8.23e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.43it/s]\n",
      "Epoch 266 Train Time 74.46170830726624s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.19it/s]Training epoch 267, Batch 1000/1000: LR=8.37e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.00it/s]\n",
      "Epoch 267 Train Time 76.942138671875s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:16<00:00, 12.67it/s]Training epoch 268, Batch 1000/1000: LR=8.36e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.03it/s]\n",
      "Epoch 268 Train Time 76.7630500793457s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 13.29it/s]Training epoch 269, Batch 1000/1000: LR=8.35e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.97it/s]\n",
      "Epoch 269 Train Time 77.1091079711914s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:16<00:00, 13.44it/s]Training epoch 270, Batch 1000/1000: LR=8.34e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.05it/s]\n",
      "Epoch 270 Train Time 76.63034129142761s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.05it/s]Training epoch 271, Batch 1000/1000: LR=8.32e-05, Loss=8.28e-02 BER=3.14e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 271 Train Time 75.96826195716858s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 12.93it/s]Training epoch 272, Batch 1000/1000: LR=8.31e-05, Loss=8.28e-02 BER=3.15e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.16it/s]\n",
      "Epoch 272 Train Time 75.96895360946655s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.24it/s]Training epoch 273, Batch 1000/1000: LR=8.30e-05, Loss=8.26e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.20it/s]\n",
      "Epoch 273 Train Time 65.80582189559937s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 13.27it/s]Training epoch 274, Batch 1000/1000: LR=8.29e-05, Loss=8.18e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:10<00:00, 14.19it/s]\n",
      "Epoch 274 Train Time 70.47386693954468s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 13.14it/s]Training epoch 275, Batch 1000/1000: LR=8.28e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.83it/s]\n",
      "Epoch 275 Train Time 77.91613578796387s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:17<00:00, 13.00it/s]Training epoch 276, Batch 1000/1000: LR=8.26e-05, Loss=8.25e-02 BER=3.14e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.89it/s]\n",
      "Epoch 276 Train Time 77.57571697235107s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.02it/s]Training epoch 277, Batch 1000/1000: LR=8.25e-05, Loss=8.25e-02 BER=3.15e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.05it/s]\n",
      "Epoch 277 Train Time 76.60846781730652s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.50it/s]Training epoch 278, Batch 1000/1000: LR=8.24e-05, Loss=8.26e-02 BER=3.15e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.11it/s]\n",
      "Epoch 278 Train Time 76.28541588783264s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.11it/s]Training epoch 279, Batch 1000/1000: LR=8.23e-05, Loss=8.28e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.06it/s]\n",
      "Epoch 279 Train Time 76.57447338104248s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.16it/s]Training epoch 280, Batch 1000/1000: LR=8.22e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.19it/s]\n",
      "Epoch 280 Train Time 75.78965377807617s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:12<00:00, 15.79it/s]Training epoch 281, Batch 1000/1000: LR=8.21e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:12<00:00, 13.72it/s]\n",
      "Epoch 281 Train Time 72.90587425231934s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.68it/s]Training epoch 282, Batch 1000/1000: LR=8.19e-05, Loss=8.25e-02 BER=3.15e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.53it/s]\n",
      "Epoch 282 Train Time 64.40551257133484s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:03<00:00, 15.26it/s]Training epoch 283, Batch 1000/1000: LR=8.18e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 283 Train Time 63.66069722175598s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.18it/s]Training epoch 284, Batch 1000/1000: LR=8.17e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.51it/s]\n",
      "Epoch 284 Train Time 64.4820306301117s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.42it/s]Training epoch 285, Batch 1000/1000: LR=8.16e-05, Loss=8.24e-02 BER=3.14e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.43it/s]\n",
      "Epoch 285 Train Time 64.82677054405212s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.32it/s]Training epoch 286, Batch 1000/1000: LR=8.14e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.34it/s]\n",
      "Epoch 286 Train Time 65.17866349220276s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.04it/s]Training epoch 287, Batch 1000/1000: LR=8.13e-05, Loss=8.24e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.40it/s]\n",
      "Epoch 287 Train Time 64.94052028656006s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.70it/s]Training epoch 288, Batch 1000/1000: LR=8.12e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.22it/s]\n",
      "Epoch 288 Train Time 65.68632674217224s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.70it/s]Training epoch 289, Batch 1000/1000: LR=8.11e-05, Loss=8.23e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.20it/s]\n",
      "Epoch 289 Train Time 65.7770369052887s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.30it/s]Training epoch 290, Batch 1000/1000: LR=8.10e-05, Loss=8.16e-02 BER=3.10e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.32it/s]\n",
      "Epoch 290 Train Time 65.2767596244812s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 15.71it/s]Training epoch 291, Batch 1000/1000: LR=8.08e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.66it/s]\n",
      "Epoch 291 Train Time 68.22808051109314s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.95it/s]Training epoch 292, Batch 1000/1000: LR=8.07e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.42it/s]\n",
      "Epoch 292 Train Time 64.86220717430115s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 12.90it/s]Training epoch 293, Batch 1000/1000: LR=8.06e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.37it/s]\n",
      "Epoch 293 Train Time 65.07735252380371s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.34it/s]Training epoch 294, Batch 1000/1000: LR=8.05e-05, Loss=8.21e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.23it/s]\n",
      "Epoch 294 Train Time 65.6776430606842s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.94it/s]Training epoch 295, Batch 1000/1000: LR=8.03e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.61it/s]\n",
      "Epoch 295 Train Time 64.07640719413757s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.42it/s]Training epoch 296, Batch 1000/1000: LR=8.02e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.05it/s]\n",
      "Epoch 296 Train Time 66.46032667160034s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.87it/s]Training epoch 297, Batch 1000/1000: LR=8.01e-05, Loss=8.16e-02 BER=3.10e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.60it/s]\n",
      "Epoch 297 Train Time 64.10630488395691s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.99it/s]Training epoch 298, Batch 1000/1000: LR=8.00e-05, Loss=8.19e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 298 Train Time 63.71920084953308s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.79it/s]Training epoch 299, Batch 1000/1000: LR=7.98e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.43it/s]\n",
      "Epoch 299 Train Time 64.79859352111816s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.71it/s]Training epoch 300, Batch 1000/1000: LR=7.97e-05, Loss=8.21e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.62it/s]\n",
      "Epoch 300 Train Time 64.04299783706665s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.47it/s]Training epoch 301, Batch 1000/1000: LR=7.96e-05, Loss=8.30e-02 BER=3.16e-02 FER=4.16e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.48it/s]\n",
      "Epoch 301 Train Time 64.58855295181274s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 13.60it/s]Training epoch 302, Batch 1000/1000: LR=7.95e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:11<00:00, 14.08it/s]\n",
      "Epoch 302 Train Time 71.03463315963745s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.52it/s]Training epoch 303, Batch 1000/1000: LR=7.93e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 303 Train Time 75.45050501823425s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.49it/s]Training epoch 304, Batch 1000/1000: LR=7.92e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Epoch 304 Train Time 75.71157097816467s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:11<00:00, 15.75it/s]Training epoch 305, Batch 1000/1000: LR=7.91e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:12<00:00, 13.87it/s]\n",
      "Epoch 305 Train Time 72.08166122436523s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.39it/s]Training epoch 306, Batch 1000/1000: LR=7.90e-05, Loss=8.25e-02 BER=3.15e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.10it/s]\n",
      "Epoch 306 Train Time 66.21141695976257s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.62it/s]Training epoch 307, Batch 1000/1000: LR=7.88e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.44it/s]\n",
      "Epoch 307 Train Time 64.78214311599731s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 12.40it/s]Training epoch 308, Batch 1000/1000: LR=7.87e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.65it/s]\n",
      "Epoch 308 Train Time 73.24927854537964s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:16<00:00, 13.54it/s]Training epoch 309, Batch 1000/1000: LR=7.86e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:16<00:00, 13.09it/s]\n",
      "Epoch 309 Train Time 76.40013980865479s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.96it/s]Training epoch 310, Batch 1000/1000: LR=7.85e-05, Loss=8.21e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.27it/s]\n",
      "Epoch 310 Train Time 75.36398768424988s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.31it/s]Training epoch 311, Batch 1000/1000: LR=7.83e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.18it/s]\n",
      "Epoch 311 Train Time 75.84927105903625s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 11.99it/s]Training epoch 312, Batch 1000/1000: LR=7.82e-05, Loss=8.15e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.28it/s]\n",
      "Epoch 312 Train Time 75.32884073257446s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.77it/s]Training epoch 313, Batch 1000/1000: LR=7.81e-05, Loss=8.16e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n",
      "Epoch 313 Train Time 75.78437757492065s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:15<00:00, 12.97it/s]Training epoch 314, Batch 1000/1000: LR=7.79e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n",
      "Epoch 314 Train Time 75.46589779853821s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 16.06it/s]Training epoch 315, Batch 1000/1000: LR=7.78e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.73it/s]\n",
      "Epoch 315 Train Time 67.90687131881714s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.43it/s]Training epoch 316, Batch 1000/1000: LR=7.77e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.25it/s]\n",
      "Epoch 316 Train Time 65.55879807472229s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.66it/s]Training epoch 317, Batch 1000/1000: LR=7.75e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.34it/s]\n",
      "Epoch 317 Train Time 65.1737174987793s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.70it/s]Training epoch 318, Batch 1000/1000: LR=7.74e-05, Loss=8.21e-02 BER=3.11e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.46it/s]\n",
      "Epoch 318 Train Time 64.70413827896118s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:12<00:00, 12.55it/s]Training epoch 319, Batch 1000/1000: LR=7.73e-05, Loss=8.15e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:12<00:00, 13.81it/s]\n",
      "Epoch 319 Train Time 72.39909625053406s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:10<00:00, 14.91it/s]Training epoch 320, Batch 1000/1000: LR=7.72e-05, Loss=8.29e-02 BER=3.16e-02 FER=4.17e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:10<00:00, 14.17it/s]\n",
      "Epoch 320 Train Time 70.57264113426208s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:13<00:00, 13.40it/s]Training epoch 321, Batch 1000/1000: LR=7.70e-05, Loss=8.21e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.59it/s]\n",
      "Epoch 321 Train Time 73.5909333229065s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:14<00:00, 13.99it/s]Training epoch 322, Batch 1000/1000: LR=7.69e-05, Loss=8.19e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.45it/s]\n",
      "Epoch 322 Train Time 74.35214948654175s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 13.65it/s]Training epoch 323, Batch 1000/1000: LR=7.68e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.38it/s]\n",
      "Epoch 323 Train Time 74.74963426589966s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 12.84it/s]Training epoch 324, Batch 1000/1000: LR=7.66e-05, Loss=8.18e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.39it/s]\n",
      "Epoch 324 Train Time 74.70912098884583s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:15<00:00, 13.21it/s]Training epoch 325, Batch 1000/1000: LR=7.65e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "Epoch 325 Train Time 75.26859402656555s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 12.98it/s]Training epoch 326, Batch 1000/1000: LR=7.64e-05, Loss=8.12e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.48it/s]\n",
      "Epoch 326 Train Time 74.20404314994812s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:14<00:00, 12.95it/s]Training epoch 327, Batch 1000/1000: LR=7.62e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:14<00:00, 13.45it/s]\n",
      "Epoch 327 Train Time 74.37866187095642s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:09<00:00, 15.12it/s]Training epoch 328, Batch 1000/1000: LR=7.61e-05, Loss=8.20e-02 BER=3.12e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.41it/s]\n",
      "Epoch 328 Train Time 69.37788796424866s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.16it/s]Training epoch 329, Batch 1000/1000: LR=7.60e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.37it/s]\n",
      "Epoch 329 Train Time 65.06706166267395s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.90it/s]Training epoch 330, Batch 1000/1000: LR=7.58e-05, Loss=8.16e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 330 Train Time 63.67619800567627s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.61it/s]Training epoch 331, Batch 1000/1000: LR=7.57e-05, Loss=8.15e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.77it/s]\n",
      "Epoch 331 Train Time 63.40489888191223s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.50it/s]Training epoch 332, Batch 1000/1000: LR=7.56e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.82it/s]\n",
      "Epoch 332 Train Time 63.1942138671875s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.73it/s]Training epoch 333, Batch 1000/1000: LR=7.54e-05, Loss=8.20e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.79it/s]\n",
      "Epoch 333 Train Time 63.31738305091858s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 16.03it/s]Training epoch 334, Batch 1000/1000: LR=7.53e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.78it/s]\n",
      "Epoch 334 Train Time 63.37001824378967s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.88it/s]Training epoch 335, Batch 1000/1000: LR=7.52e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.39it/s]\n",
      "Epoch 335 Train Time 64.99274897575378s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.08it/s]Training epoch 336, Batch 1000/1000: LR=7.50e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.34it/s]\n",
      "Epoch 336 Train Time 65.20047235488892s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.62it/s]Training epoch 337, Batch 1000/1000: LR=7.49e-05, Loss=8.19e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.34it/s]\n",
      "Epoch 337 Train Time 65.19770908355713s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.94it/s]Training epoch 338, Batch 1000/1000: LR=7.48e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.24it/s]\n",
      "Epoch 338 Train Time 65.61020112037659s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.28it/s]Training epoch 339, Batch 1000/1000: LR=7.46e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.06it/s]\n",
      "Epoch 339 Train Time 66.38372993469238s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.52it/s]Training epoch 340, Batch 1000/1000: LR=7.45e-05, Loss=8.13e-02 BER=3.08e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.07it/s]\n",
      "Epoch 340 Train Time 66.34843683242798s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.48it/s]Training epoch 341, Batch 1000/1000: LR=7.43e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.44it/s]\n",
      "Epoch 341 Train Time 64.76251077651978s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.61it/s]Training epoch 342, Batch 1000/1000: LR=7.42e-05, Loss=8.07e-02 BER=3.07e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.78it/s]\n",
      "Epoch 342 Train Time 63.38487458229065s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.83it/s]Training epoch 343, Batch 1000/1000: LR=7.41e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.21it/s]\n",
      "Epoch 343 Train Time 65.74875664710999s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.34it/s]Training epoch 344, Batch 1000/1000: LR=7.39e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.14e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.80it/s]\n",
      "Epoch 344 Train Time 67.5619466304779s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.75it/s]Training epoch 345, Batch 1000/1000: LR=7.38e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.99it/s]\n",
      "Epoch 345 Train Time 66.73509526252747s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.43it/s]Training epoch 346, Batch 1000/1000: LR=7.37e-05, Loss=8.21e-02 BER=3.13e-02 FER=4.15e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.54it/s]\n",
      "Epoch 346 Train Time 64.3611536026001s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.62it/s]Training epoch 347, Batch 1000/1000: LR=7.35e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 347 Train Time 63.47994780540466s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.48it/s]Training epoch 348, Batch 1000/1000: LR=7.34e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.07it/s]\n",
      "Epoch 348 Train Time 66.35795450210571s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.90it/s]Training epoch 349, Batch 1000/1000: LR=7.32e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.31it/s]\n",
      "Epoch 349 Train Time 65.31638360023499s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 16.01it/s]Training epoch 350, Batch 1000/1000: LR=7.31e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.76it/s]\n",
      "Epoch 350 Train Time 63.46903610229492s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.33it/s]Training epoch 351, Batch 1000/1000: LR=7.30e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.54it/s]\n",
      "Epoch 351 Train Time 64.37199926376343s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.62it/s]Training epoch 352, Batch 1000/1000: LR=7.28e-05, Loss=8.15e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.66it/s]\n",
      "Epoch 352 Train Time 63.85394501686096s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.29it/s]Training epoch 353, Batch 1000/1000: LR=7.27e-05, Loss=8.16e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "Epoch 353 Train Time 66.0628764629364s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.45it/s]Training epoch 354, Batch 1000/1000: LR=7.26e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.53it/s]\n",
      "Epoch 354 Train Time 64.38031101226807s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.42it/s]Training epoch 355, Batch 1000/1000: LR=7.24e-05, Loss=8.20e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.83it/s]\n",
      "Epoch 355 Train Time 67.447336435318s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.17it/s]Training epoch 356, Batch 1000/1000: LR=7.23e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.92it/s]\n",
      "Epoch 356 Train Time 67.00878238677979s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.12it/s]Training epoch 357, Batch 1000/1000: LR=7.21e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.41it/s]\n",
      "Epoch 357 Train Time 64.88008213043213s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.11it/s]Training epoch 358, Batch 1000/1000: LR=7.20e-05, Loss=8.15e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.27it/s]\n",
      "Epoch 358 Train Time 65.5095534324646s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.86it/s]Training epoch 359, Batch 1000/1000: LR=7.19e-05, Loss=8.11e-02 BER=3.08e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.67it/s]\n",
      "Epoch 359 Train Time 63.82626914978027s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.73it/s]Training epoch 360, Batch 1000/1000: LR=7.17e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n",
      "Epoch 360 Train Time 63.56324028968811s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.64it/s]Training epoch 361, Batch 1000/1000: LR=7.16e-05, Loss=8.19e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.78it/s]\n",
      "Epoch 361 Train Time 63.35979104042053s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.48it/s]Training epoch 362, Batch 1000/1000: LR=7.14e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.74it/s]\n",
      "Epoch 362 Train Time 63.52489924430847s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.86it/s]Training epoch 363, Batch 1000/1000: LR=7.13e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.19it/s]\n",
      "Epoch 363 Train Time 65.81676626205444s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.35it/s]Training epoch 364, Batch 1000/1000: LR=7.12e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.63it/s]\n",
      "Epoch 364 Train Time 63.963619232177734s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.91it/s]Training epoch 365, Batch 1000/1000: LR=7.10e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.48it/s]\n",
      "Epoch 365 Train Time 64.5843460559845s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.95it/s]Training epoch 366, Batch 1000/1000: LR=7.09e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 366 Train Time 63.79215455055237s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.45it/s]Training epoch 367, Batch 1000/1000: LR=7.07e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 367 Train Time 63.71276330947876s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.13it/s]Training epoch 368, Batch 1000/1000: LR=7.06e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.76it/s]\n",
      "Epoch 368 Train Time 63.443360328674316s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:03<00:00, 15.50it/s]Training epoch 369, Batch 1000/1000: LR=7.04e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 369 Train Time 63.68139863014221s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.96it/s]Training epoch 370, Batch 1000/1000: LR=7.03e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 370 Train Time 63.62329816818237s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 16.00it/s]Training epoch 371, Batch 1000/1000: LR=7.02e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 371 Train Time 63.67752933502197s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.58it/s]Training epoch 372, Batch 1000/1000: LR=7.00e-05, Loss=8.12e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 372 Train Time 63.51134157180786s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.87it/s]Training epoch 373, Batch 1000/1000: LR=6.99e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.66it/s]\n",
      "Epoch 373 Train Time 63.84278059005737s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.45it/s]Training epoch 374, Batch 1000/1000: LR=6.97e-05, Loss=8.08e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.76it/s]\n",
      "Epoch 374 Train Time 63.47287178039551s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.52it/s]Training epoch 375, Batch 1000/1000: LR=6.96e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.76it/s]\n",
      "Epoch 375 Train Time 63.45216917991638s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.24it/s]Training epoch 376, Batch 1000/1000: LR=6.94e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.65it/s]\n",
      "Epoch 376 Train Time 63.90326976776123s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.46it/s]Training epoch 377, Batch 1000/1000: LR=6.93e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 377 Train Time 63.74790644645691s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.72it/s]Training epoch 378, Batch 1000/1000: LR=6.92e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 378 Train Time 63.674683809280396s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.34it/s]Training epoch 379, Batch 1000/1000: LR=6.90e-05, Loss=8.22e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 379 Train Time 63.72150540351868s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.45it/s]Training epoch 380, Batch 1000/1000: LR=6.89e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 380 Train Time 63.650516748428345s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 16.07it/s]Training epoch 381, Batch 1000/1000: LR=6.87e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 381 Train Time 63.6454393863678s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.85it/s]Training epoch 382, Batch 1000/1000: LR=6.86e-05, Loss=8.12e-02 BER=3.09e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 382 Train Time 63.500880002975464s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.71it/s]Training epoch 383, Batch 1000/1000: LR=6.84e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 383 Train Time 63.62683701515198s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.49it/s]Training epoch 384, Batch 1000/1000: LR=6.83e-05, Loss=8.08e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 384 Train Time 63.71882963180542s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.60it/s]Training epoch 385, Batch 1000/1000: LR=6.81e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 385 Train Time 63.710196018218994s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.89it/s]Training epoch 386, Batch 1000/1000: LR=6.80e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 386 Train Time 63.79233193397522s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.94it/s]Training epoch 387, Batch 1000/1000: LR=6.79e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 387 Train Time 63.59788680076599s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.69it/s]Training epoch 388, Batch 1000/1000: LR=6.77e-05, Loss=8.16e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 388 Train Time 63.6336727142334s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:03<00:00, 15.19it/s]Training epoch 389, Batch 1000/1000: LR=6.76e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 389 Train Time 63.477941036224365s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.80it/s]Training epoch 390, Batch 1000/1000: LR=6.74e-05, Loss=8.19e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 390 Train Time 63.48730802536011s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.93it/s]Training epoch 391, Batch 1000/1000: LR=6.73e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 391 Train Time 63.61165809631348s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.15it/s]Training epoch 392, Batch 1000/1000: LR=6.71e-05, Loss=8.23e-02 BER=3.14e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 392 Train Time 63.75326752662659s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.70it/s]Training epoch 393, Batch 1000/1000: LR=6.70e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 393 Train Time 63.76521563529968s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.28it/s]Training epoch 394, Batch 1000/1000: LR=6.68e-05, Loss=8.19e-02 BER=3.13e-02 FER=4.13e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.66it/s]\n",
      "Epoch 394 Train Time 63.85286998748779s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.49it/s]Training epoch 395, Batch 1000/1000: LR=6.67e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 395 Train Time 63.76074767112732s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.86it/s]Training epoch 396, Batch 1000/1000: LR=6.65e-05, Loss=8.19e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.67it/s]\n",
      "Epoch 396 Train Time 63.81088209152222s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 16.00it/s]Training epoch 397, Batch 1000/1000: LR=6.64e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.59it/s]\n",
      "Epoch 397 Train Time 64.15839982032776s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.67it/s]Training epoch 398, Batch 1000/1000: LR=6.62e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.67it/s]\n",
      "Epoch 398 Train Time 63.79945135116577s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.88it/s]Training epoch 399, Batch 1000/1000: LR=6.61e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 399 Train Time 63.61296272277832s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.63it/s]Training epoch 400, Batch 1000/1000: LR=6.59e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 400 Train Time 63.665668964385986s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.93it/s]Training epoch 401, Batch 1000/1000: LR=6.58e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.63it/s]\n",
      "Epoch 401 Train Time 64.0001266002655s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.84it/s]Training epoch 402, Batch 1000/1000: LR=6.56e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.65it/s]\n",
      "Epoch 402 Train Time 63.89949107170105s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.75it/s]Training epoch 403, Batch 1000/1000: LR=6.55e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.63it/s]\n",
      "Epoch 403 Train Time 63.967735052108765s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.82it/s]Training epoch 404, Batch 1000/1000: LR=6.54e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n",
      "Epoch 404 Train Time 63.57404398918152s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.73it/s]Training epoch 405, Batch 1000/1000: LR=6.52e-05, Loss=8.20e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 405 Train Time 63.615564823150635s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.47it/s]Training epoch 406, Batch 1000/1000: LR=6.51e-05, Loss=8.17e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.47it/s]\n",
      "Epoch 406 Train Time 64.64954853057861s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.78it/s]Training epoch 407, Batch 1000/1000: LR=6.49e-05, Loss=8.16e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 407 Train Time 63.757232427597046s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.92it/s]Training epoch 408, Batch 1000/1000: LR=6.48e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 408 Train Time 63.69191122055054s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.66it/s]Training epoch 409, Batch 1000/1000: LR=6.46e-05, Loss=8.16e-02 BER=3.10e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.67it/s]\n",
      "Epoch 409 Train Time 63.82763695716858s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.26it/s]Training epoch 410, Batch 1000/1000: LR=6.45e-05, Loss=8.07e-02 BER=3.07e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.74it/s]\n",
      "Epoch 410 Train Time 63.54928469657898s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.73it/s]Training epoch 411, Batch 1000/1000: LR=6.43e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.78it/s]\n",
      "Epoch 411 Train Time 63.36842942237854s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.84it/s]Training epoch 412, Batch 1000/1000: LR=6.42e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.69it/s]\n",
      "Epoch 412 Train Time 63.72035217285156s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.52it/s]Training epoch 413, Batch 1000/1000: LR=6.40e-05, Loss=8.10e-02 BER=3.08e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n",
      "Epoch 413 Train Time 63.57305598258972s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 14.73it/s]Training epoch 414, Batch 1000/1000: LR=6.39e-05, Loss=8.19e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 414 Train Time 63.65895986557007s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.49it/s]Training epoch 415, Batch 1000/1000: LR=6.37e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 415 Train Time 63.7818877696991s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.66it/s]Training epoch 416, Batch 1000/1000: LR=6.36e-05, Loss=8.11e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n",
      "Epoch 416 Train Time 63.56503176689148s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.66it/s]Training epoch 417, Batch 1000/1000: LR=6.34e-05, Loss=8.08e-02 BER=3.08e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.66it/s]\n",
      "Epoch 417 Train Time 63.859901905059814s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.91it/s]Training epoch 418, Batch 1000/1000: LR=6.33e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.74it/s]\n",
      "Epoch 418 Train Time 63.52154016494751s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.25it/s]Training epoch 419, Batch 1000/1000: LR=6.31e-05, Loss=8.09e-02 BER=3.08e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.78it/s]\n",
      "Epoch 419 Train Time 67.67999219894409s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.15it/s]Training epoch 420, Batch 1000/1000: LR=6.30e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "Epoch 420 Train Time 66.0421416759491s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.21it/s]Training epoch 421, Batch 1000/1000: LR=6.28e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.05it/s]\n",
      "Epoch 421 Train Time 66.45190119743347s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.48it/s]Training epoch 422, Batch 1000/1000: LR=6.27e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.36it/s]\n",
      "Epoch 422 Train Time 65.0954384803772s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.07it/s]Training epoch 423, Batch 1000/1000: LR=6.25e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.18it/s]\n",
      "Epoch 423 Train Time 65.89770603179932s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.30it/s]Training epoch 424, Batch 1000/1000: LR=6.24e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.09it/s]\n",
      "Epoch 424 Train Time 66.2661943435669s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.27it/s]Training epoch 425, Batch 1000/1000: LR=6.22e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.27it/s]\n",
      "Epoch 425 Train Time 65.5024483203888s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.61it/s]Training epoch 426, Batch 1000/1000: LR=6.21e-05, Loss=8.18e-02 BER=3.13e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.54it/s]\n",
      "Epoch 426 Train Time 64.3356511592865s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.62it/s]Training epoch 427, Batch 1000/1000: LR=6.19e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.52it/s]\n",
      "Epoch 427 Train Time 64.41814064979553s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.72it/s]Training epoch 428, Batch 1000/1000: LR=6.18e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.49it/s]\n",
      "Epoch 428 Train Time 64.55361557006836s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.70it/s]Training epoch 429, Batch 1000/1000: LR=6.16e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.33it/s]\n",
      "Epoch 429 Train Time 65.22320914268494s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.57it/s]Training epoch 430, Batch 1000/1000: LR=6.14e-05, Loss=8.09e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.45it/s]\n",
      "Epoch 430 Train Time 64.74317765235901s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 12.68it/s]Training epoch 431, Batch 1000/1000: LR=6.13e-05, Loss=8.12e-02 BER=3.09e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.85it/s]\n",
      "Epoch 431 Train Time 67.33703136444092s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.64it/s]Training epoch 432, Batch 1000/1000: LR=6.11e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.19it/s]\n",
      "Epoch 432 Train Time 65.83937692642212s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.71it/s]Training epoch 433, Batch 1000/1000: LR=6.10e-05, Loss=8.15e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.04it/s]\n",
      "Epoch 433 Train Time 66.48343467712402s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.38it/s]Training epoch 434, Batch 1000/1000: LR=6.08e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.44it/s]\n",
      "Epoch 434 Train Time 64.7677891254425s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.64it/s]Training epoch 435, Batch 1000/1000: LR=6.07e-05, Loss=8.08e-02 BER=3.09e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.61it/s]\n",
      "Epoch 435 Train Time 64.05090594291687s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 13.85it/s]Training epoch 436, Batch 1000/1000: LR=6.05e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.17it/s]\n",
      "Epoch 436 Train Time 65.91182494163513s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.70it/s]Training epoch 437, Batch 1000/1000: LR=6.04e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.32it/s]\n",
      "Epoch 437 Train Time 65.26890277862549s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 14.89it/s]Training epoch 438, Batch 1000/1000: LR=6.02e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.67it/s]\n",
      "Epoch 438 Train Time 68.1523540019989s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:04<00:00, 14.88it/s]Training epoch 439, Batch 1000/1000: LR=6.01e-05, Loss=8.12e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.41it/s]\n",
      "Epoch 439 Train Time 64.89119005203247s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.55it/s]Training epoch 440, Batch 1000/1000: LR=5.99e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "Epoch 440 Train Time 66.05903720855713s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.83it/s]Training epoch 441, Batch 1000/1000: LR=5.98e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n",
      "Epoch 441 Train Time 63.57804584503174s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 12.71it/s]Training epoch 442, Batch 1000/1000: LR=5.96e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.50it/s]\n",
      "Epoch 442 Train Time 64.51626420021057s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.81it/s]Training epoch 443, Batch 1000/1000: LR=5.95e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.53it/s]\n",
      "Epoch 443 Train Time 64.39598894119263s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.56it/s]Training epoch 444, Batch 1000/1000: LR=5.93e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.34it/s]\n",
      "Epoch 444 Train Time 65.21228551864624s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.42it/s]Training epoch 445, Batch 1000/1000: LR=5.92e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.36it/s]\n",
      "Epoch 445 Train Time 65.12521958351135s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.99it/s]Training epoch 446, Batch 1000/1000: LR=5.90e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.98it/s]\n",
      "Epoch 446 Train Time 66.74865412712097s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.14it/s]Training epoch 447, Batch 1000/1000: LR=5.89e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.88it/s]\n",
      "Epoch 447 Train Time 67.21103191375732s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.24it/s]Training epoch 448, Batch 1000/1000: LR=5.87e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.17it/s]\n",
      "Epoch 448 Train Time 65.93143010139465s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 13.31it/s]Training epoch 449, Batch 1000/1000: LR=5.86e-05, Loss=8.06e-02 BER=3.07e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.27it/s]\n",
      "Epoch 449 Train Time 65.49037384986877s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.12it/s]Training epoch 450, Batch 1000/1000: LR=5.84e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.89it/s]\n",
      "Epoch 450 Train Time 67.15684700012207s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.28it/s]Training epoch 451, Batch 1000/1000: LR=5.82e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.25it/s]\n",
      "Epoch 451 Train Time 65.57575726509094s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.07it/s]Training epoch 452, Batch 1000/1000: LR=5.81e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.48it/s]\n",
      "Epoch 452 Train Time 64.61287069320679s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.58it/s]Training epoch 453, Batch 1000/1000: LR=5.79e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.51it/s]\n",
      "Epoch 453 Train Time 64.47377228736877s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.33it/s]Training epoch 454, Batch 1000/1000: LR=5.78e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.05e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.54it/s]\n",
      "Epoch 454 Train Time 64.35627484321594s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.72it/s]Training epoch 455, Batch 1000/1000: LR=5.76e-05, Loss=8.07e-02 BER=3.07e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.31it/s]\n",
      "Epoch 455 Train Time 65.3313500881195s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.53it/s]Training epoch 456, Batch 1000/1000: LR=5.75e-05, Loss=8.16e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.58it/s]\n",
      "Epoch 456 Train Time 64.19282531738281s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:03<00:00, 15.73it/s]Training epoch 457, Batch 1000/1000: LR=5.73e-05, Loss=8.13e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 457 Train Time 63.674126625061035s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.92it/s]Training epoch 458, Batch 1000/1000: LR=5.72e-05, Loss=8.17e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "Epoch 458 Train Time 66.04581999778748s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.89it/s]Training epoch 459, Batch 1000/1000: LR=5.70e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.55it/s]\n",
      "Epoch 459 Train Time 64.30859804153442s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:06<00:00, 12.80it/s]Training epoch 460, Batch 1000/1000: LR=5.69e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.04it/s]\n",
      "Epoch 460 Train Time 66.48717975616455s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.95it/s]Training epoch 461, Batch 1000/1000: LR=5.67e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.13it/s]\n",
      "Epoch 461 Train Time 66.0852267742157s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.57it/s]Training epoch 462, Batch 1000/1000: LR=5.65e-05, Loss=8.09e-02 BER=3.08e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 462 Train Time 63.47767615318298s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.96it/s]Training epoch 463, Batch 1000/1000: LR=5.64e-05, Loss=8.18e-02 BER=3.13e-02 FER=4.11e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.42it/s]\n",
      "Epoch 463 Train Time 64.87433791160583s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.67it/s]Training epoch 464, Batch 1000/1000: LR=5.62e-05, Loss=8.03e-02 BER=3.06e-02 FER=4.05e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.68it/s]\n",
      "Epoch 464 Train Time 63.77591347694397s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.86it/s]Training epoch 465, Batch 1000/1000: LR=5.61e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.62it/s]\n",
      "Epoch 465 Train Time 64.02295851707458s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.47it/s]Training epoch 466, Batch 1000/1000: LR=5.59e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.57it/s]\n",
      "Epoch 466 Train Time 64.23332834243774s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.33it/s]Training epoch 467, Batch 1000/1000: LR=5.58e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.67it/s]\n",
      "Epoch 467 Train Time 63.799670934677124s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.11it/s]Training epoch 468, Batch 1000/1000: LR=5.56e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.60it/s]\n",
      "Epoch 468 Train Time 64.08902382850647s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.69it/s]Training epoch 469, Batch 1000/1000: LR=5.55e-05, Loss=8.10e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.72it/s]\n",
      "Epoch 469 Train Time 63.618621826171875s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.58it/s]Training epoch 470, Batch 1000/1000: LR=5.53e-05, Loss=8.15e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.75it/s]\n",
      "Epoch 470 Train Time 63.506712675094604s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.78it/s]Training epoch 471, Batch 1000/1000: LR=5.52e-05, Loss=8.16e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.47it/s]\n",
      "Epoch 471 Train Time 64.62786436080933s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.60it/s]Training epoch 472, Batch 1000/1000: LR=5.50e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.71it/s]\n",
      "Epoch 472 Train Time 63.6498749256134s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:03<00:00, 15.67it/s]Training epoch 473, Batch 1000/1000: LR=5.48e-05, Loss=8.01e-02 BER=3.05e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:03<00:00, 15.70it/s]\n",
      "Epoch 473 Train Time 63.713122844696045s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.00it/s]Training epoch 474, Batch 1000/1000: LR=5.47e-05, Loss=8.14e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.15it/s]\n",
      "Epoch 474 Train Time 66.00737357139587s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.59it/s]Training epoch 475, Batch 1000/1000: LR=5.45e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.37it/s]\n",
      "Epoch 475 Train Time 65.0675437450409s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.94it/s]Training epoch 476, Batch 1000/1000: LR=5.44e-05, Loss=8.09e-02 BER=3.10e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.57it/s]\n",
      "Epoch 476 Train Time 64.21459746360779s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 14.62it/s]Training epoch 477, Batch 1000/1000: LR=5.42e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.35it/s]\n",
      "Epoch 477 Train Time 65.14315390586853s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.44it/s]Training epoch 478, Batch 1000/1000: LR=5.41e-05, Loss=8.02e-02 BER=3.05e-02 FER=4.04e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.95it/s]\n",
      "Epoch 478 Train Time 66.90956091880798s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.62it/s]Training epoch 479, Batch 1000/1000: LR=5.39e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.11it/s]\n",
      "Epoch 479 Train Time 66.19418931007385s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.10it/s]Training epoch 480, Batch 1000/1000: LR=5.38e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.59it/s]\n",
      "Epoch 480 Train Time 64.14994597434998s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:09<00:00, 14.05it/s]Training epoch 481, Batch 1000/1000: LR=5.36e-05, Loss=8.08e-02 BER=3.08e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.44it/s]\n",
      "Epoch 481 Train Time 69.26620221138s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 15.68it/s]Training epoch 482, Batch 1000/1000: LR=5.35e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.56it/s]\n",
      "Epoch 482 Train Time 68.69233059883118s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.58it/s]Training epoch 483, Batch 1000/1000: LR=5.33e-05, Loss=8.08e-02 BER=3.08e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.30it/s]\n",
      "Epoch 483 Train Time 65.36929821968079s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.72it/s]Training epoch 484, Batch 1000/1000: LR=5.31e-05, Loss=8.08e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.25it/s]\n",
      "Epoch 484 Train Time 65.57370257377625s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.83it/s]Training epoch 485, Batch 1000/1000: LR=5.30e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.47it/s]\n",
      "Epoch 485 Train Time 64.63559889793396s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.45it/s]Training epoch 486, Batch 1000/1000: LR=5.28e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.08it/s]\n",
      "Epoch 486 Train Time 66.30405569076538s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.47it/s]Training epoch 487, Batch 1000/1000: LR=5.27e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.12it/s]\n",
      "Epoch 487 Train Time 66.12427401542664s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 14.76it/s]Training epoch 488, Batch 1000/1000: LR=5.25e-05, Loss=8.14e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.37it/s]\n",
      "Epoch 488 Train Time 65.06795763969421s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.37it/s]Training epoch 489, Batch 1000/1000: LR=5.24e-05, Loss=8.13e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.35it/s]\n",
      "Epoch 489 Train Time 65.15660071372986s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.85it/s]Training epoch 490, Batch 1000/1000: LR=5.22e-05, Loss=8.05e-02 BER=3.06e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "Epoch 490 Train Time 66.04010343551636s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.14it/s]Training epoch 491, Batch 1000/1000: LR=5.21e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.29it/s]\n",
      "Epoch 491 Train Time 65.40232563018799s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.34it/s]Training epoch 492, Batch 1000/1000: LR=5.19e-05, Loss=8.18e-02 BER=3.12e-02 FER=4.12e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.78it/s]\n",
      "Epoch 492 Train Time 67.65146017074585s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 14.96it/s]Training epoch 493, Batch 1000/1000: LR=5.17e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 15.04it/s]\n",
      "Epoch 493 Train Time 66.51267504692078s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.17it/s]Training epoch 494, Batch 1000/1000: LR=5.16e-05, Loss=8.13e-02 BER=3.11e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.98it/s]\n",
      "Epoch 494 Train Time 66.73875403404236s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:04<00:00, 15.69it/s]Training epoch 495, Batch 1000/1000: LR=5.14e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:04<00:00, 15.51it/s]\n",
      "Epoch 495 Train Time 64.48653149604797s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 14.62it/s]Training epoch 496, Batch 1000/1000: LR=5.13e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.88it/s]\n",
      "Epoch 496 Train Time 67.23005366325378s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:09<00:00, 14.60it/s]Training epoch 497, Batch 1000/1000: LR=5.11e-05, Loss=8.11e-02 BER=3.10e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.32it/s]\n",
      "Epoch 497 Train Time 69.8335177898407s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:06<00:00, 15.34it/s]Training epoch 498, Batch 1000/1000: LR=5.10e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:06<00:00, 14.98it/s]\n",
      "Epoch 498 Train Time 66.76082682609558s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:09<00:00, 13.07it/s]Training epoch 499, Batch 1000/1000: LR=5.08e-05, Loss=8.12e-02 BER=3.10e-02 FER=4.10e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:09<00:00, 14.33it/s]\n",
      "Epoch 499 Train Time 69.76467275619507s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:08<00:00, 15.62it/s]Training epoch 500, Batch 1000/1000: LR=5.07e-05, Loss=8.11e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:08<00:00, 14.50it/s]\n",
      "Epoch 500 Train Time 68.95320200920105s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:05<00:00, 15.24it/s]Training epoch 501, Batch 1000/1000: LR=5.05e-05, Loss=8.05e-02 BER=3.07e-02 FER=4.05e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.30it/s]\n",
      "Epoch 501 Train Time 65.36502194404602s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 14.76it/s]Training epoch 502, Batch 1000/1000: LR=5.03e-05, Loss=8.10e-02 BER=3.09e-02 FER=4.09e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.89it/s]\n",
      "Epoch 502 Train Time 67.16442155838013s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 15.17it/s]Training epoch 503, Batch 1000/1000: LR=5.02e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.06e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.84it/s]\n",
      "Epoch 503 Train Time 67.37988066673279s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:07<00:00, 12.70it/s]Training epoch 504, Batch 1000/1000: LR=5.00e-05, Loss=8.09e-02 BER=3.09e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:07<00:00, 14.83it/s]\n",
      "Epoch 504 Train Time 67.43701076507568s\n",
      "\n",
      "Training: 100%|█████████▉| 998/1000 [01:17<00:00, 11.85it/s]Training epoch 505, Batch 1000/1000: LR=4.99e-05, Loss=8.08e-02 BER=3.08e-02 FER=4.07e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.89it/s]\n",
      "Epoch 505 Train Time 77.6115095615387s\n",
      "\n",
      "Training: 100%|█████████▉| 999/1000 [01:20<00:00, 12.03it/s]Training epoch 506, Batch 1000/1000: LR=4.97e-05, Loss=8.07e-02 BER=3.08e-02 FER=4.08e-01\n",
      "Training: 100%|██████████| 1000/1000 [01:20<00:00, 12.40it/s]\n",
      "Epoch 506 Train Time 80.6625816822052s\n",
      "\n",
      "Training:   9%|▊         | 87/1000 [00:07<01:16, 11.97it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(args: Config, model: torch.nn.Module):\n",
    "    code = args.code\n",
    "    initial_lr = args.warmup_lr\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    optimizer = Adam(model.parameters(), lr=args.warmup_lr)\n",
    "\n",
    "    # model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
    "    # optimizer.load_state_dict(torch.load(os.path.join(config.path, 'optimizer_checkpoint')))\n",
    "    \n",
    "\n",
    "    #################################\n",
    "    EbNo_range_test = range(4, 7)\n",
    "    EbNo_range_train = range(2, 8)\n",
    "    std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
    "    std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
    "    train_dataloader = DataLoader(ECC_Dataset(code, std_train, len=args.batch_size * 1000, zero_cw=True), batch_size=int(args.batch_size),\n",
    "                                  shuffle=True, num_workers=args.workers)\n",
    "    test_dataloader_list = [DataLoader(ECC_Dataset(code, [std_test[ii]], len=int(args.test_batch_size), zero_cw=False),\n",
    "                                       batch_size=int(args.test_batch_size), shuffle=False, num_workers=args.workers) for ii in range(len(std_test))]\n",
    "    #################################\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    # for epoch in range(1,3):\n",
    "    #     loss, ber, fer = train(model, device, train_dataloader, optimizer,\n",
    "    #                            epoch, LR=initial_lr, config=args)\n",
    "    #     if loss < best_loss:\n",
    "    #         best_loss = loss\n",
    "    #         torch.save(model.state_dict(), os.path.join(args.path, 'best_model'))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = args.lr\n",
    "    \n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=1000, eta_min=args.eta_min)\n",
    "    # scheduler.load_state_dict(torch.load(os.path.join(config.path, 'scheduler_checkpoint')))\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        loss, ber, fer = train(model, device, train_dataloader, optimizer,\n",
    "                               epoch, LR=scheduler.get_last_lr()[0], config=args)\n",
    "        scheduler.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), os.path.join(args.path, 'best_model'))\n",
    "            torch.save(optimizer.state_dict(), os.path.join(args.path, 'optimizer_checkpoint'))\n",
    "            torch.save(scheduler.state_dict(), os.path.join(args.path, 'scheduler_checkpoint'))\n",
    "\n",
    "        # if epoch % 200 == 0:\n",
    "        #     test(model, device, test_dataloader_list, EbNo_range_test)\n",
    "    return model\n",
    "\n",
    "train_model(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_808/1964912410.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Test EbN0=0, BER=1.60e-01 -ln(BER)=1.83e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "Test EbN0=1, BER=1.29e-01 -ln(BER)=2.05e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Test EbN0=2, BER=8.35e-02 -ln(BER)=2.48e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Test EbN0=3, BER=5.69e-02 -ln(BER)=2.87e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Test EbN0=4, BER=2.95e-02 -ln(BER)=3.52e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Test EbN0=5, BER=1.12e-02 -ln(BER)=4.49e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "Test EbN0=6, BER=3.51e-03 -ln(BER)=5.65e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Test EbN0=7, BER=7.17e-04 -ln(BER)=7.24e+00\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "/tmp/ipykernel_808/1964912410.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  ln_ber = -np.log(test_ber)\n",
      "Test EbN0=8, BER=0.00e+00 -ln(BER)=inf\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "Test EbN0=9, BER=0.00e+00 -ln(BER)=inf\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Test EbN0=10, BER=0.00e+00 -ln(BER)=inf\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dataset import bin_to_sign, BER, FER\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def test(model, device, test_loader_list, EbNo_range_test, min_FER=100):\n",
    "    model.eval()\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        for ii, test_loader in enumerate(test_loader_list):\n",
    "            test_loss = test_ber = test_fer = cum_count = 0.\n",
    "            for m, x, z, y, magnitude, syndrome in tqdm(test_loader, position=0, leave=True, desc=\"Testing\"):\n",
    "                z_mul = -(y * bin_to_sign(x))\n",
    "                z_pred = model(magnitude.to(device), syndrome.to(device))\n",
    "                loss, x_pred = model.loss(-z_pred, z_mul.to(device), y.to(device))\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                test_ber += BER(x_pred, x.to(device))\n",
    "                test_fer += FER(x_pred, x.to(device))\n",
    "            ln_ber = -np.log(test_ber)\n",
    "            logging.info(f'Test EbN0={EbNo_range_test[ii]}, BER={test_ber:.2e} -ln(BER)={ln_ber:.2e}')\n",
    "\n",
    "def _test(config, model):\n",
    "    EbNo_range_test = range(0, 11)\n",
    "    code = config.code\n",
    "    std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
    "    test_dataloader_list = [DataLoader(ECC_Dataset(code, [std_test[ii]], len=int(config.test_batch_size), zero_cw=False),\n",
    "                                        batch_size=int(config.test_batch_size), shuffle=False, num_workers=config.workers) for ii in range(len(std_test))]\n",
    "    test(model, 'cuda', test_dataloader_list, EbNo_range_test)\n",
    "model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
    "_test(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_808/2858039931.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ECCM(config=config)\n",
    "model.load_state_dict(torch.load(os.path.join(config.path, 'best_model')))\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49]) torch.Size([1, 49])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4088, 0.8753, 1.1154, 1.1782, 0.5120, 1.5581, 0.5942, 0.6546, 0.6640,\n",
       "         0.0324, 0.9378, 0.6654, 0.7365, 0.6614, 0.6114, 1.6320, 2.6217, 0.7731,\n",
       "         0.8895, 1.2220, 0.5241, 1.4081, 0.8772, 1.9551, 0.1367, 0.6679, 1.0144,\n",
       "         1.2929, 0.6523, 0.7113, 1.0940, 2.1230, 0.1073, 1.2876, 1.2061, 0.5629,\n",
       "         0.5588, 1.1120, 1.2857, 0.3438, 0.8440, 0.9382, 0.5116, 0.9380, 0.0501,\n",
       "         0.4033, 0.5285, 0.7348, 2.0556]),\n",
       " tensor([ 1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.]),\n",
       " tensor([[ 7.1580,  7.5678,  6.7079,  6.5955,  6.2516,  6.8364,  7.2832,  7.2998,\n",
       "           7.9689, -4.8371,  7.5992,  7.2584,  7.8876,  7.3152,  6.2642,  8.1351,\n",
       "           7.6308,  7.9487,  7.3857,  9.6573,  6.0551,  6.5745,  7.4570,  7.5394,\n",
       "           5.6933,  7.3272,  6.6034,  7.3792,  6.2857,  7.4604,  6.4929,  7.7946,\n",
       "           6.8777,  7.3587,  6.8430,  7.1945,  6.5008,  6.7291,  7.5036,  6.2470,\n",
       "           6.3437,  7.4382,  7.2722,  6.5850,  4.7441,  7.2464,  6.3119,  7.3956,\n",
       "           7.2431]], device='cuda:0', grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[ 0.4088,  0.8753,  1.1154,  1.1782,  0.5120,  1.5581,  0.5942,  0.6546,\n",
       "           0.6640, -0.0324,  0.9378,  0.6654,  0.7365,  0.6614,  0.6114,  1.6320,\n",
       "           2.6217,  0.7731,  0.8895,  1.2220,  0.5241,  1.4081,  0.8772,  1.9551,\n",
       "           0.1367,  0.6679,  1.0144,  1.2929,  0.6523,  0.7113,  1.0940,  2.1230,\n",
       "           0.1073,  1.2876,  1.2061,  0.5629,  0.5588,  1.1120,  1.2857,  0.3438,\n",
       "           0.8440,  0.9382,  0.5116,  0.9380,  0.0501,  0.4033,  0.5285,  0.7348,\n",
       "           2.0556]]),\n",
       " tensor(0.0013, device='cuda:0',\n",
       "        grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]], device='cuda:0',\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import bin_to_sign\n",
    "\n",
    "code = config.code\n",
    "EbNo_range_train = [5]\n",
    "std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
    "m,x,z,y,mag,syn = ECC_Dataset(code, std_train, len=config.batch_size * 1000, zero_cw=False)[0]\n",
    "z_mul = (y * bin_to_sign(x))\n",
    "if len(z_mul.shape) < 2:\n",
    "    z_mul = z_mul.unsqueeze(0)\n",
    "z_pred = model(mag.to('cuda'), syn.to('cuda'))\n",
    "print(z_pred.shape, z_mul.shape)\n",
    "loss, x_pred = model.loss(-z_pred, z_mul.to('cuda'), y.to('cuda'))\n",
    "mag, syn, z_pred, z_mul, loss, x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f38763cb110>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(x)\n",
    "plt.plot(y<0, '--')\n",
    "plt.plot(x_pred[0].detach().cpu().numpy(), \". \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas:\n",
    "# Bi-directional\n",
    "# Load and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
